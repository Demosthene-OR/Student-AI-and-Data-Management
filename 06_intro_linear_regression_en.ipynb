{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Demosthene-OR/Student-AI-and-Data-Management/blob/main/06_intro_linear_regression_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://prof.totalenergies.com/wp-content/uploads/2024/09/TotalEnergies_TPA_picto_DegradeRouge_RVB-1024x1024.png\" height=\"150\" width=\"150\">\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Introduction to Machine Learning with scikit-learn </h1></center>\n",
    "<center><h2> Linear Regression </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> This notebook introduces the concepts of Machine Learning, and more specifically linear regression, to show how Python is a programming language well suited to machine learning problems. All of these concepts will be presented in more detail and put into practice in the modules dedicated to Machine Learning.\n",
    ">\n",
    "> Machine learning is a subfield of artificial intelligence that enables computers to learn how to automatically perform tasks based on data. When the task to be performed is the prediction of a variable, we refer to this as supervised learning.\n",
    ">\n",
    "> Linear regression is one of the first predictive models of supervised learning to have been studied. This model allows us to predict a quantitative variable. Today, it is the most popular model for practical applications due to its simplicity.\n",
    ">\n",
    "> In the linear regression model, we have $y$, the quantitative variable to be predicted (called the target variable), and explanatory variables that enable prediction.\n",
    "\n",
    "### Univariate Linear Regression\n",
    "\n",
    "> In the univariate linear model, we have two variables, $y$ called the target variable and $x$ called the explanatory variable. <br>\n",
    "> Linear regression consists of modeling the relationship between these two variables using an affine function. Thus, the formula for the univariate linear model is given by:\n",
    "> $$y \\approx \\beta_1 x + \\beta_0 $$\n",
    "> where:\n",
    ">> * $y$ is the variable we want to predict.\n",
    ">>\n",
    ">>\n",
    ">> * $x$ is the explanatory variable.\n",
    ">>\n",
    ">>\n",
    ">> * $\\beta_1$ and $\\beta_0$ are the parameters of the linear function. $\\beta_1$ will define its **slope** and $\\beta_0$ will define its y-intercept (also called **bias**).\n",
    ">\n",
    "> **The goal of linear regression is to estimate the best parameters $\\beta_0$ and $\\beta_1$ to predict the variable $y$ from a given value of $x$**.\n",
    ">\n",
    "> To get a feel for univariate linear regression, let's look at the interactive example below.\n",
    "\n",
    "* **(a)** Run the following cell to display the interactive figure. In this figure, we have simulated a dataset.\n",
    "\n",
    "\n",
    "* **(b)** Use the sliders on the `Regression` tab to find the parameters $\\beta_0$ and $\\beta_1$ that best fit all the points in the dataset.\n",
    "\n",
    "\n",
    "* **(c)** What is the effect of each parameter on the regression function? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/regression_widgets.py\n",
    "from regression_widgets import regression_widget_linear\n",
    "\n",
    "regression_widget_linear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "> Multiple linear regression consists of modeling the relationship between a target variable $y$ and **several explanatory variables** $x_1$, $x_2$, ... ,$x_p$, often referred to as *features*:\n",
    "> $$\n",
    "\\begin{align}\n",
    "    y & \\approx β_0 + β_1 x_1 + β_2 x_2 + ⋯ + β_p x_p \\\\\n",
    "      & \\approx β_0+ \\sum_{j=1}^{p} β_j x_j \n",
    "\\end{align}\n",
    "$$\n",
    ">\n",
    "> There are now $p + 1$ parameters $\\beta_j$ to find.\n",
    "\n",
    "\n",
    "## Using scikit-learn for linear regression\n",
    "\n",
    "> We will now learn how to use the **`scikit-learn`** library to solve a machine learning problem. In particular, we will see how useful this library is for preparing data and then implementing models.\n",
    ">\n",
    "> We are working on a project where the objective is to predict the **selling price of a car** based on its **characteristics**. The variable to be predicted is quantitative, so we are dealing with a regression problem.\n",
    "\n",
    "### Importing the dataset\n",
    "\n",
    "> The dataset we will use below contains many characteristics about different cars from 1985.\n",
    ">\n",
    "> For simplicity, only numerical variables have been kept and rows with missing values have been removed.\n",
    "\n",
    "* **(a)** Import the `pandas` module under the alias `pd`.\n",
    "\n",
    "\n",
    "* **(b)** In a `DataFrame` named `df`, import the `automobiles.csv` dataset using the `read_csv` function from `pandas`. This file is located in the same folder as the execution environment for this notebook.\n",
    "\n",
    "\n",
    "* **(c)** Display the first 5 rows of `df` to verify that the import was successful.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/data/\"\n",
    "df = pd.read_csv(url+\"automobiles.csv\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "> * The variable `symboling` corresponds to the degree of risk to the insurer (risk of accident, breakdown, etc.).\n",
    ">\n",
    ">\n",
    "> * The variable `normalized_losses` is the average relative annual cost of insuring the vehicle. This value is normalized in relation to cars of the same type (SUV, utility vehicle, sports car, etc.).\n",
    ">\n",
    ">\n",
    "> * The following 13 variables relate to the technical characteristics of the cars, such as width, length, engine size, horsepower, etc.\n",
    ">\n",
    ">\n",
    "> * The last variable, `price`, corresponds to the sale price of the vehicle. This is the variable we will be trying to predict.\n",
    "\n",
    "\n",
    "### Separating the explanatory variables from the target variable\n",
    "\n",
    "> We will now create two `DataFrames`, one containing the explanatory variables and another containing the target variable `price`.\n",
    "\n",
    "* **(d)** In a `DataFrame` named `X`, make a copy of the explanatory variables in our dataset, i.e., all variables **except** `price`.\n",
    "\n",
    "\n",
    "* **(e)** In a `Series` named `y`, make a copy of the target variable `price`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explanatory variables\n",
    "X = df.drop(['price'], axis = 1)\n",
    "\n",
    "# Target variable\n",
    "y = df['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Separating data into training and test sets\n",
    "\n",
    "> We will now separate our dataset into two parts: a **training** set and a **test** set. This step is **extremely** important in data science.\n",
    ">\n",
    "> As their names suggest: \n",
    ">> * the training part is used to “train” the model, i.e., find the optimal parameters $\\beta_0$, ..., $\\beta_p$ for this dataset.\n",
    ">>\n",
    ">>\n",
    ">> * The test part is used to “test” the trained model by evaluating its ability to **generalize** its predictions on data it has **never seen** before.\n",
    ">\n",
    "> A very useful function for performing this operation is the `train_test_split` function from the `model_selection` submodule of **`scikit-learn`**.\n",
    "\n",
    "* **(f)** Run the following cell to import the `train_test_split` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "> This function is used as follows:\n",
    ">\n",
    "> ```python\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "> ```\n",
    ">\n",
    "> * `X_train` and `y_train` are the explanatory and target variables of the **training** dataset.\n",
    ">\n",
    ">\n",
    "> * `X_test` and `y_test` are the explanatory and target variables of the **test** dataset.\n",
    ">>\n",
    ">>\n",
    ">> * The `test_size` argument corresponds to the **proportion** of the dataset that we want to keep for the test set. In the previous example, this proportion corresponds to 20% of the initial dataset.\n",
    ">>\n",
    ">>\n",
    ">> * The `random_state` argument ensures that the data split can be reproduced. Since the operation is random, two successive splits will theoretically give two different results. As long as the value of `random_state` is the same (regardless of what that value is), the result of the train_test_split function will remain the same.\n",
    "\n",
    "* **(g)** Using the `train_test_split` function, split the dataset into a training set (`X_train`,`y_train`)  and a test set (`X_test`, `y_test`) so that the test set contains **15% of the initial dataset**. Specify the parameter `random_state = 42`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data separation into training (85%) and test game (15%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Creating the regression model\n",
    "\n",
    "> To train a linear regression model on this dataset, we will use the **`LinearRegression`** class contained in the `linear_model` submodule of `scikit-learn`.\n",
    "\n",
    "* **(h)** Run the following cell to import the `LinearRegression` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "> L'API de `scikit-learn` permet d'entraîner et évaluer des modèles très facilement. Toutes les classes de modèles de scikit-learn disposent des deux méthodes suivantes :\n",
    ">> * **`fit`** : Entraîne le modèle sur un jeu de données. \n",
    ">>\n",
    ">>\n",
    ">> * **`predict`** : Effectue une prédiction à partir de variables explicatives. \n",
    ">\n",
    "> Voici un exemple d'utilisation d'un modèle avec scikit-learn :\n",
    "> \n",
    "> ```python\n",
    "># Instanciation du modèle\n",
    "> linreg = LinearRegression()      \n",
    ">    \n",
    "># Entraînement du modèle sur le jeu d'entraînement\n",
    "> linreg.fit(X_train, y_train)        \n",
    ">  \n",
    "># Prédiction de la variable cible pour le jeu de données test. Ces prédictions sont stockées dans y_pred\n",
    "> y_pred = linreg.predict(X_test)                                           \n",
    ">    ```\n",
    "\n",
    "* **(i)** Instancier un modèle `LinearRegression` nommé **`lr`**.\n",
    "\n",
    "\n",
    "* **(j)** Entraîner `lr` sur le jeu de données d'entraînement.\n",
    "\n",
    "\n",
    "* **(k)** Effectuer une prédiction sur les données d'entraînement. Stocker ces prédictions dans `y_pred_train`.\n",
    "\n",
    "\n",
    "* **(l)** Effectuer une prédiction sur les données de test. Stocker ces prédictions dans `y_pred_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Model training\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of the target variable for train dataset\n",
    "y_pred_train = lr.predict(X_train)\n",
    "\n",
    "# Prediction of the target variable for the testing dataset\n",
    "y_pred_test = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Evaluating model performance\n",
    "\n",
    "> In order to evaluate the **quality of the model's predictions** obtained using the parameters $\\beta_0$, ..., $\\beta_j$, there are several metrics available in the `scikit-learn` library.\n",
    ">\n",
    "> One of the most commonly used metrics for regression is **Mean Squared Error**, which exists under the name `mean_squared_error` in the `metrics` submodule of `scikit-learn`.\n",
    ">\n",
    "> This function calculates the average of the differences between the **true values** of the target variable and the **predicted values** using the regression function. The mean squared error is simply the average of these distances squared.\n",
    ">\n",
    "> The `mean_squared_error` function in `scikit-learn` is used as follows:\n",
    ">\n",
    "> ```python\n",
    "    mean_squared_error(y_true, y_pred)\n",
    "> ```\n",
    "> where:\n",
    ">> * `y_true` corresponds to the true values of the target variable.\n",
    ">>\n",
    ">>\n",
    ">> * `y_pred` corresponds to the values predicted by our model.\n",
    "\n",
    "* **(o)** Import the **`mean_squared_error`** function from the `sklearn.metrics` submodule.\n",
    "\n",
    "\n",
    "* **(p)** Evaluate the prediction quality of the model on **the training data**. Store the result in a variable named `mse_train`.\n",
    "\n",
    "\n",
    "* **(q)** Evaluate the model's prediction quality on **the test data**. Store the result in a variable named `mse_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculation the MSE between the target variable values in the train dataset and the prediction on X_train\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculation of the MSE between the target variable values in the test dataset and the prediction on X_test\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"MSE train lr:\", mse_train)\n",
    "print(\"MSE test lr:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "> The mean squared error you find should be several million on the test data, which can be difficult to interpret. \n",
    ">\n",
    "> That's why we're going to use another metric, the **mean absolute error**, which directly calculates the absolute value differences between the true values of the target variable and the predicted values.\n",
    "\n",
    "* **(s)** Import the `mean_absolute_error` function from the `sklearn.metrics` submodule.\n",
    "\n",
    "\n",
    "* **(t)** Evaluate the prediction quality on the test and training data using the mean absolute error.\n",
    "\n",
    "\n",
    "* **(u)** From the `DataFrame` `df`, calculate the average purchase price for all vehicles. Do the model's predictions seem reliable to you?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculation of MAE between the true values of the target variable of the train and the prediction on X_train\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculation of the MAE between the true values of the target variable of the test and the prediction on X_test\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"MAE train lr:\", mae_train)\n",
    "print(\"MAE test lr:\", mae_test)\n",
    "\n",
    "mean_price = df['price'].mean()\n",
    "\n",
    "print(\"\\nRelative error\", mae_test / mean_price)\n",
    "\n",
    "# The average error is around 14% of the average price, which is not optimal\n",
    "# but is still a good baseline for testing more advanced models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Conclusion and recap\n",
    "\n",
    "> In this notebook, we introduced how to solve a machine learning problem. \n",
    "> \n",
    "> The different steps we studied are the classic steps of any project:\n",
    ">\n",
    "> * Data exploration with the `Pandas` library\n",
    ">\n",
    "> * Data preparation by separating the explanatory variables from the target variable\n",
    ">\n",
    "> * Splitting the dataset into two (a training set and a test set) using the `train_test_split` function from the `scikit-learn` library\n",
    ">\n",
    "> * Identifying the type of problem: in this case, regression\n",
    ">\n",
    "> * Instantiating a model such as `LinearRegression` with the `scikit-learn` library\n",
    ">\n",
    "> * Training the model on the training dataset using the `fit` method.\n",
    ">\n",
    "> * Predicting the test data using the `predict` method.\n",
    ">\n",
    "> * Evaluating the model's performance by calculating the error between these predictions and the actual values of the target variable in the test data. Evaluation for a regression model is easily done using the `mean_squared_error` or `mean_absolute_error` functions from the `metrics` submodule of scikit-learn.\n",
    ">\n",
    "> In the next notebook, we will perform the same steps but for solving a machine learning classification problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
