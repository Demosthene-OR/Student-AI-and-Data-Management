{
 "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Demosthene-OR/Student-AI-and-Data-Management/blob/main/sklearn_classif_04_decision_tree_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": true,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://prof.totalenergies.com/wp-content/uploads/2024/09/TotalEnergies_TPA_picto_DegradeRouge_RVB-1024x1024.png\" height=\"150\" width=\"150\">\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h1 style = \"text-align:center\" >Scikit-Learn: classification models</h1> \n",
    "<h2 style = \"text-align:center\">Decision trees</h2> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    ">In this exercise we will study an example of using decision trees under Python.<br>\n",
    "> The packages used will be **pandas**, **scikit-learn** and his sub-packages, in particular **tree** and **model_selection**.\n",
    "\n",
    "><div class=\"alert alert-success\">\n",
    "<i class=\"fa fa-question-circle\"></i> &emsp; \n",
    "A major advantage of decision trees is that they can be calculated automatically from databases by supervised learning algorithms.<br>\n",
    "These algorithms automatically select the discriminating variables from unstructured and potentially bulky data. They can thus make it possible to extract logic rules of cause and effect (determinisms) which did not initially appear in raw data.\n",
    "</div>\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">0. Introduction to dataset</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    ">The database used in this exercise comes from the [UCI ML Restitry](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) and contains data calculated from digitized images of breast masses.<br>\n",
    "> They describe the characteristics of the cell nuclei present in each image (radius, perimeter, texture, etc.)\n",
    "La première colonne donne le résultat du diagnostic de chaque masse cellulaire : 'B' for *benign*, 'M' for *malignant*. <br>\n",
    "> The objective of the exercise is to build a model in the form of a decision tree, to predict whether a cellular mass is benign or smart, depending on the characteristics calculated from the image of its biopsy.\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">1. Data preparation and modeling</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "* **(a)** Load the function **train_test_split** from the under module **sklearn.model_selection**.\n",
    "\n",
    "\n",
    "* **(b)** Load the class **DecisionTreeClassifier** From the submodle **sklearn.tree**.\n",
    "\n",
    "\n",
    "* **(c)** Load the library **pandas** under the name **`pd`**.\n",
    "\n",
    "\n",
    "* **(d)** Read the file *Breast_cancer.csv* in a dataframe named **`bc_data`**.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp; \n",
    "Remember that before looking at the solution, you can always access the official Python help by typing <code style = \"background-color: transparent ; color : inherit\"><b>help(name_function)</b></code> in the console.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/\"\n",
    "bc_data = pd.read_csv(url+'breast_cancer.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "* **(e)** Show information from Data Frame **bc_data**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 569 entries, 842302 to 92751\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    object \n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 142.2+ KB\n"
     ]
    }
   ],
   "source": [
    "bc_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    ">No variable contains missing values.<br>\n",
    ">All the variables, with the exception of 'diagnosis' are continuous variables, but the decisions of decisions work as well with discreet or qualitative variables (after dichotomization on *scikit-learn*).<br>\n",
    "> A glance at the first lines of the data frame shows us that the different variables are not on the same scale, but very little \"preprocessing\" is necessary during a classification by decision tree.\n",
    "\n",
    "* **(f)** Create the data frame **data** containing the different *features* and the vector **target** containing the target variable **'diagnosis'**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "data = bc_data.drop('diagnosis', axis=1)\n",
    "target = bc_data.diagnosis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">2. Building a decision tree</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    ">In machine learning, a decision tree can be described as a visual representation of a data classification algorithm according to different criteria called decisions (or nodes).<br>Each node corresponds to a test on a learning variable, and each of the following branches represents a result of this test. Each leaf of the tree (terminal nodes) contains a value of the target variable (a label in the case of a classification).\n",
    ">\n",
    "> During the training of the model, the nodes are created from \"optimal\" tests compared to the training set, and the latter ends when the leaves of the trees are homogeneous or check a certain stop criterion.\n",
    ">\n",
    "> This decision tree therefore allows, after training on a set of data, to easily carry out predictions in the form of successive logic rules of classification. The results are thus easily interpretable and therefore exploitable, communication around easier modeling. It is therefore a very appreciated classifier used in business.\n",
    ">\n",
    "> The construction of a decision tree is done in principle in 2 phases:\n",
    ">\n",
    "> The **First phase** consists of building nodes:\n",
    ">> * From a learning set is engaged in a recursive process of division of the space of data in samples increasingly pure in terms of classes, on the basis of a predefined criterion.\n",
    ">>\n",
    ">>\n",
    ">> * The classification problem is thus broken down into a sequence of (nested) tests relating to a variable, type \"`x> = threshold`\".\n",
    ">>\n",
    ">>\n",
    ">> * On each node, the best test is selected from a certain criterion (often based on the theory of\n",
    "Information, and in particular on the concept of entropy), the objective of which is to reduce the mixture of classes as much as possible within each subset created by the different alternatives of the test.\n",
    ">>\n",
    ">>\n",
    ">> * follows a succession of classifications in the form of a tree, each end of which (or \"leaf\") indicates belonging to a class.\n",
    ">>\n",
    ">>\n",
    ">> * The class allocated to a sheet is determined by the class mainly represented among the data of the learning set which \"fall\" in this sheet.\n",
    ">>\n",
    ">>\n",
    ">> The objective of this phase is to generate a hierarchical sequence of tests, as short as possible, which successively divides all the learning data into disjoint sub-assemblies, such as cases of cases belonging to the same class are quickly detected.\n",
    ">\n",
    "> The **second phase** is pruning :\n",
    ">> * It consists of removing branches that are not very representative in order to maintain good predictive performance. This step requires the creation of a criterion/metric to designate the branches to be pruned, which will depend on the algorithm used.\n",
    ">>\n",
    ">>\n",
    ">> * After pruning, the branches are replaced by terminal nodes, labeled on the basis of the distribution of learning data (majority class).\n",
    ">>\n",
    ">>\n",
    ">> * In general, the pruningis from the bottom to the top of the tree (\"Bottom-up\"). It is based on an estimate (crossed validation, new sample, statistical estimate, ...) of the classification error rate: a tree is pruned to a certain node if the error rate estimated at this node (by allocating the majority class) is lower than the error rate obtained by considering the terminal subarbres.\n",
    ">>\n",
    ">>\n",
    ">> * The pruning is successively extended (from the ends) until all the remaining subarbres satisfy the condition on classification error rates.\n",
    "\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">3. Data learning</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> The function [`DecisionTreeClassifier`](http://scikit-learn.org/stable/modles/generated/sklearn.tree.decisionreeClassify.html) allows to create a classifier based on a decision tree. Many parameters can be specified, such as the 'criterion' for evaluating partitions, the maximum depth of the tree, the number of *features* to consider at each node, etc.\n",
    "\n",
    "* **(a)** Run the following cell to visualize the influence of hyperparameters on a decision tree model.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<i class=\"fa fa-info-circle\"></i> &emsp;\n",
    "The datasets contain two classes (red dots/blue dots) with <b>x0</b> and <b>x1</b> as features. The background color represents the probability of belonging to one of the classes. The redder the color, the greater the probability of belonging to class 2.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-09-15 02:43:23--  https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/interactions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20555 (20K) [text/plain]\n",
      "Saving to: 'interactions.py.1'\n",
      "\n",
      "     0K .......... ..........                                 100% 19,2M=0,001s\n",
      "\n",
      "2025-09-15 02:43:23 (19,2 MB/s) - 'interactions.py.1' saved [20555/20555]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27005554699f4001a043cab00814edc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(VBox(children=(HTML(value='<b>Hyperparameters</b>'), HTML(value=''), D…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!wget https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/interactions.py\n",
    "\n",
    "from interactions import show_tree\n",
    "show_tree()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "* **(b)** separate the data set into learning and testing sets, so that the test set represents 20% of the total data.\n",
    "Add the argument `random_state =123` in the function **`train_test_split`** for the reproducibility of the choice of random.\n",
    "\n",
    "\n",
    "* **(c)** Create a DecisionTreeClassifier instance named **dt_clf**, with the criterion `criterion='entropy'` and the argument `max_Depth = 4` to specify the maximum number of separation points possible before reaching a leaf node.\n",
    "Again, add the argument `random_state =123` for the reproducibility of the results.\n",
    "\n",
    "\n",
    "* **(d)** Train the classifier on the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=123)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion ='entropy', max_depth=4, random_state=123)\n",
    "dt_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "* **(e)** Apply the model to the data set data and store the predictions obtained in the variable **`y_pred`**.\n",
    "\n",
    "\n",
    "* **(f)** Show a confusion matrix to compare the real and predicted classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Class</th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Class   B   M\n",
       "Actual Class           \n",
       "B                72   1\n",
       "M                 3  38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual Class'], colnames=['Predicted Class'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    ">The predictions made on the test sample are encouraging.<br>\n",
    ">To find out which variables have the most determined the 'diagnosis' of each cell mass, the attribute **`feature_importance_`** returns the ***importance*** normalized of each variable in the construction of the tree.<br>\n",
    "> In *scikit-learn* the **importance** is defined as the total decrease of the impurity criterion between a node and the next two nodes used to split the node. The greater the difference between the impurity calculated for a node and its ‘child’ nodes, the greater the variable used to divide the node.\n",
    "\n",
    "* **(g)** Show the 8 most important variables for **`dt_clf`** , as well as their respective importance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.620770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.177674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.060736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.051408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.041369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius_se</th>\n",
       "      <td>0.020865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.016107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_se</th>\n",
       "      <td>0.011072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Importance\n",
       "radius_worst            0.620770\n",
       "concave points_worst    0.177674\n",
       "concavity_mean          0.060736\n",
       "texture_mean            0.051408\n",
       "texture_worst           0.041369\n",
       "radius_se               0.020865\n",
       "area_worst              0.016107\n",
       "compactness_se          0.011072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = {}\n",
    "for feature, importance in zip(data.columns, dt_clf.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "    \n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})\n",
    "importances.sort_values(by='Importance', ascending=False).head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(25,12))\n",
    "\n",
    "from sklearn import tree\n",
    "tree.plot_tree(dt_clf,feature_names=data.columns);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1152pt\" height=\"552pt\"\n",
       " viewBox=\"0.00 0.00 1152.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 1148,-548 1148,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f5cdb0\" stroke=\"black\" d=\"M631.5,-544C631.5,-544 506.5,-544 506.5,-544 500.5,-544 494.5,-538 494.5,-532 494.5,-532 494.5,-473 494.5,-473 494.5,-467 500.5,-461 506.5,-461 506.5,-461 631.5,-461 631.5,-461 637.5,-461 643.5,-467 643.5,-473 643.5,-473 643.5,-532 643.5,-532 643.5,-538 637.5,-544 631.5,-544\"/>\n",
       "<text text-anchor=\"start\" x=\"502.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">radius_worst ≤ 16.795</text>\n",
       "<text text-anchor=\"start\" x=\"521.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.955</text>\n",
       "<text text-anchor=\"start\" x=\"524\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 455</text>\n",
       "<text text-anchor=\"start\" x=\"514.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [284, 171]</text>\n",
       "<text text-anchor=\"start\" x=\"539.5\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e88d4c\" stroke=\"black\" d=\"M512.5,-425C512.5,-425 341.5,-425 341.5,-425 335.5,-425 329.5,-419 329.5,-413 329.5,-413 329.5,-354 329.5,-354 329.5,-348 335.5,-342 341.5,-342 341.5,-342 512.5,-342 512.5,-342 518.5,-342 524.5,-348 524.5,-354 524.5,-354 524.5,-413 524.5,-413 524.5,-419 518.5,-425 512.5,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"337.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">concave points_worst ≤ 0.136</text>\n",
       "<text text-anchor=\"start\" x=\"379.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.434</text>\n",
       "<text text-anchor=\"start\" x=\"382\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 302</text>\n",
       "<text text-anchor=\"start\" x=\"376.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [275, 27]</text>\n",
       "<text text-anchor=\"start\" x=\"397.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M519.73,-460.91C508.28,-451.47 495.99,-441.34 484.22,-431.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"486.12,-428.68 476.18,-425.02 481.67,-434.08 486.12,-428.68\"/>\n",
       "<text text-anchor=\"middle\" x=\"478.58\" y=\"-446.21\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#45a3e7\" stroke=\"black\" d=\"M809,-425C809,-425 669,-425 669,-425 663,-425 657,-419 657,-413 657,-413 657,-354 657,-354 657,-348 663,-342 669,-342 669,-342 809,-342 809,-342 815,-342 821,-348 821,-354 821,-354 821,-413 821,-413 821,-419 815,-425 809,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"665\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">concavity_mean ≤ 0.072</text>\n",
       "<text text-anchor=\"start\" x=\"691.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.323</text>\n",
       "<text text-anchor=\"start\" x=\"694\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 153</text>\n",
       "<text text-anchor=\"start\" x=\"692\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 144]</text>\n",
       "<text text-anchor=\"start\" x=\"711\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>0&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M627.98,-460.91C642.09,-451.2 657.26,-440.76 671.71,-430.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"673.87,-433.57 680.12,-425.02 669.9,-427.81 673.87,-433.57\"/>\n",
       "<text text-anchor=\"middle\" x=\"675.58\" y=\"-445.91\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e5833c\" stroke=\"black\" d=\"M264,-306C264,-306 132,-306 132,-306 126,-306 120,-300 120,-294 120,-294 120,-235 120,-235 120,-229 126,-223 132,-223 132,-223 264,-223 264,-223 270,-223 276,-229 276,-235 276,-235 276,-294 276,-294 276,-300 270,-306 264,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">texture_mean ≤ 21.435</text>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.113</text>\n",
       "<text text-anchor=\"start\" x=\"153\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 264</text>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [260, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"168.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M347.55,-341.91C327.41,-331.62 305.66,-320.51 285.16,-310.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.65,-306.86 276.15,-305.43 283.46,-313.09 286.65,-306.86\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#baddf6\" stroke=\"black\" d=\"M484.5,-306C484.5,-306 369.5,-306 369.5,-306 363.5,-306 357.5,-300 357.5,-294 357.5,-294 357.5,-235 357.5,-235 357.5,-229 363.5,-223 369.5,-223 369.5,-223 484.5,-223 484.5,-223 490.5,-223 496.5,-229 496.5,-235 496.5,-235 496.5,-294 496.5,-294 496.5,-300 490.5,-306 484.5,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"365.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">texture_worst ≤ 26.9</text>\n",
       "<text text-anchor=\"start\" x=\"379.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.968</text>\n",
       "<text text-anchor=\"start\" x=\"386\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n",
       "<text text-anchor=\"start\" x=\"380\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 23]</text>\n",
       "<text text-anchor=\"start\" x=\"399\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M427,-341.91C427,-333.65 427,-324.86 427,-316.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"430.5,-316.02 427,-306.02 423.5,-316.02 430.5,-316.02\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M98,-179.5C98,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 98,-111.5 98,-111.5 104,-111.5 110,-117.5 110,-123.5 110,-123.5 110,-167.5 110,-167.5 110,-173.5 104,-179.5 98,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"15\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 212</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [212, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"25.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.39,-222.91C133.82,-210.99 117.91,-197.98 103.42,-186.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.49,-183.29 95.54,-179.67 101.06,-188.71 105.49,-183.29\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e78c49\" stroke=\"black\" d=\"M256,-187C256,-187 140,-187 140,-187 134,-187 128,-181 128,-175 128,-175 128,-116 128,-116 128,-110 134,-104 140,-104 140,-104 256,-104 256,-104 262,-104 268,-110 268,-116 268,-116 268,-175 268,-175 268,-181 262,-187 256,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"136\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">area_worst ≤ 646.45</text>\n",
       "<text text-anchor=\"start\" x=\"150.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.391</text>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 52</text>\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"168.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198,-222.91C198,-214.65 198,-205.86 198,-197.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.5,-197.02 198,-187.02 194.5,-197.02 201.5,-197.02\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M127,-68C127,-68 49,-68 49,-68 43,-68 37,-62 37,-56 37,-56 37,-12 37,-12 37,-6 43,0 49,0 49,0 127,0 127,0 133,0 139,-6 139,-12 139,-12 139,-56 139,-56 139,-62 133,-68 127,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"48\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n",
       "<text text-anchor=\"start\" x=\"45\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"58.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.04,-103.73C147.79,-94.51 137.96,-84.74 128.72,-75.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131.01,-72.87 121.45,-68.3 126.07,-77.84 131.01,-72.87\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#eca572\" stroke=\"black\" d=\"M256.5,-68C256.5,-68 169.5,-68 169.5,-68 163.5,-68 157.5,-62 157.5,-56 157.5,-56 157.5,-12 157.5,-12 157.5,-6 163.5,0 169.5,0 169.5,0 256.5,0 256.5,0 262.5,0 268.5,-6 268.5,-12 268.5,-12 268.5,-56 268.5,-56 268.5,-62 262.5,-68 256.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"165.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.764</text>\n",
       "<text text-anchor=\"start\" x=\"172\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"183.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.59,-103.73C204.72,-95.43 205.92,-86.67 207.07,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.55,-78.68 208.44,-68.3 203.61,-77.73 210.55,-78.68\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#f1bc95\" stroke=\"black\" d=\"M469.5,-187C469.5,-187 298.5,-187 298.5,-187 292.5,-187 286.5,-181 286.5,-175 286.5,-175 286.5,-116 286.5,-116 286.5,-110 292.5,-104 298.5,-104 298.5,-104 469.5,-104 469.5,-104 475.5,-104 481.5,-110 481.5,-116 481.5,-116 481.5,-175 481.5,-175 481.5,-181 475.5,-187 469.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"294.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">concave points_worst ≤ 0.181</text>\n",
       "<text text-anchor=\"start\" x=\"336.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.902</text>\n",
       "<text text-anchor=\"start\" x=\"343\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n",
       "<text text-anchor=\"start\" x=\"341\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 7]</text>\n",
       "<text text-anchor=\"start\" x=\"354.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M412.08,-222.91C408.95,-214.38 405.6,-205.28 402.36,-196.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"405.63,-195.2 398.89,-187.02 399.06,-197.61 405.63,-195.2\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M590,-179.5C590,-179.5 512,-179.5 512,-179.5 506,-179.5 500,-173.5 500,-167.5 500,-167.5 500,-123.5 500,-123.5 500,-117.5 506,-111.5 512,-111.5 512,-111.5 590,-111.5 590,-111.5 596,-111.5 602,-117.5 602,-123.5 602,-123.5 602,-167.5 602,-167.5 602,-173.5 596,-179.5 590,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"511\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"510\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n",
       "<text text-anchor=\"start\" x=\"508\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 16]</text>\n",
       "<text text-anchor=\"start\" x=\"523\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M470.02,-222.91C482.42,-211.21 495.93,-198.46 508.31,-186.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.98,-189.08 515.85,-179.67 506.17,-183.98 510.98,-189.08\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#ea9a61\" stroke=\"black\" d=\"M409,-68C409,-68 329,-68 329,-68 323,-68 317,-62 317,-56 317,-56 317,-12 317,-12 317,-6 323,0 329,0 329,0 409,0 409,0 415,0 421,-6 421,-12 421,-12 421,-56 421,-56 421,-62 415,-68 409,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"325\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.65</text>\n",
       "<text text-anchor=\"start\" x=\"328\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"339.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M378.41,-103.73C377.28,-95.43 376.08,-86.67 374.93,-78.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"378.39,-77.73 373.56,-68.3 371.45,-78.68 378.39,-77.73\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M523,-68C523,-68 451,-68 451,-68 445,-68 439,-62 439,-56 439,-56 439,-12 439,-12 439,-6 445,0 451,0 451,0 523,0 523,0 529,0 535,-6 535,-12 535,-12 535,-56 535,-56 535,-62 529,-68 523,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"447\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"449.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n",
       "<text text-anchor=\"start\" x=\"447.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"459\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M422.35,-103.73C430.93,-94.61 440.03,-84.93 448.61,-75.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"451.37,-77.98 455.68,-68.3 446.28,-73.19 451.37,-77.98\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M805,-306C805,-306 673,-306 673,-306 667,-306 661,-300 661,-294 661,-294 661,-235 661,-235 661,-229 667,-223 673,-223 673,-223 805,-223 805,-223 811,-223 817,-229 817,-235 817,-235 817,-294 817,-294 817,-300 811,-306 805,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"669\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">texture_mean ≤ 18.835</text>\n",
       "<text text-anchor=\"start\" x=\"699\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n",
       "<text text-anchor=\"start\" x=\"698\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n",
       "<text text-anchor=\"start\" x=\"699.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"709.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M739,-341.91C739,-333.65 739,-324.86 739,-316.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"742.5,-316.02 739,-306.02 735.5,-316.02 742.5,-316.02\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<path fill=\"#3a9ee5\" stroke=\"black\" d=\"M1018,-306C1018,-306 918,-306 918,-306 912,-306 906,-300 906,-294 906,-294 906,-235 906,-235 906,-229 912,-223 918,-223 918,-223 1018,-223 1018,-223 1024,-223 1030,-229 1030,-235 1030,-235 1030,-294 1030,-294 1030,-300 1024,-306 1018,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"914\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">radius_se ≤ 0.192</text>\n",
       "<text text-anchor=\"start\" x=\"920.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.062</text>\n",
       "<text text-anchor=\"start\" x=\"923\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 137</text>\n",
       "<text text-anchor=\"start\" x=\"921\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 136]</text>\n",
       "<text text-anchor=\"start\" x=\"940\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>12&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M818.45,-341.91C843.88,-328.92 871.86,-314.62 896.67,-301.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"898.34,-305.02 905.65,-297.35 895.16,-298.79 898.34,-305.02\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M704,-179.5C704,-179.5 632,-179.5 632,-179.5 626,-179.5 620,-173.5 620,-167.5 620,-167.5 620,-123.5 620,-123.5 620,-117.5 626,-111.5 632,-111.5 632,-111.5 704,-111.5 704,-111.5 710,-111.5 716,-117.5 716,-123.5 716,-123.5 716,-167.5 716,-167.5 716,-173.5 710,-179.5 704,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"628\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"630.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n",
       "<text text-anchor=\"start\" x=\"628.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"638.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M714.37,-222.91C707.6,-211.76 700.26,-199.66 693.45,-188.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"696.31,-186.4 688.13,-179.67 690.32,-190.03 696.31,-186.4\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"#52a9e8\" stroke=\"black\" d=\"M889.5,-187C889.5,-187 746.5,-187 746.5,-187 740.5,-187 734.5,-181 734.5,-175 734.5,-175 734.5,-116 734.5,-116 734.5,-110 740.5,-104 746.5,-104 746.5,-104 889.5,-104 889.5,-104 895.5,-104 901.5,-110 901.5,-116 901.5,-116 901.5,-175 901.5,-175 901.5,-181 895.5,-187 889.5,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"742.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">compactness_se ≤ 0.021</text>\n",
       "<text text-anchor=\"start\" x=\"770.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.503</text>\n",
       "<text text-anchor=\"start\" x=\"780.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n",
       "<text text-anchor=\"start\" x=\"778.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"790\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M766.41,-222.91C772.41,-214.01 778.83,-204.51 785.03,-195.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"787.94,-197.27 790.64,-187.02 782.14,-193.35 787.94,-197.27\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M797,-68C797,-68 725,-68 725,-68 719,-68 713,-62 713,-56 713,-56 713,-12 713,-12 713,-6 719,0 725,0 725,0 797,0 797,0 803,0 809,-6 809,-12 809,-12 809,-56 809,-56 809,-62 803,-68 797,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"721\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"723.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n",
       "<text text-anchor=\"start\" x=\"721.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"733\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M796.78,-103.73C792.26,-95.06 787.49,-85.9 782.96,-77.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"786.06,-75.55 778.33,-68.3 779.85,-78.79 786.06,-75.55\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M911,-68C911,-68 839,-68 839,-68 833,-68 827,-62 827,-56 827,-56 827,-12 827,-12 827,-6 833,0 839,0 839,0 911,0 911,0 917,0 923,-6 923,-12 923,-12 923,-56 923,-56 923,-62 917,-68 911,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"835\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"837.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"835.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"845.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M839.22,-103.73C843.74,-95.06 848.51,-85.9 853.04,-77.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"856.15,-78.79 857.67,-68.3 849.94,-75.55 856.15,-78.79\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M1004,-179.5C1004,-179.5 932,-179.5 932,-179.5 926,-179.5 920,-173.5 920,-167.5 920,-167.5 920,-123.5 920,-123.5 920,-117.5 926,-111.5 932,-111.5 932,-111.5 1004,-111.5 1004,-111.5 1010,-111.5 1016,-117.5 1016,-123.5 1016,-123.5 1016,-167.5 1016,-167.5 1016,-173.5 1010,-179.5 1004,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"928\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"930.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"928.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"938.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = M</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M968,-222.91C968,-212.2 968,-200.62 968,-189.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"971.5,-189.67 968,-179.67 964.5,-189.67 971.5,-189.67\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1132,-179.5C1132,-179.5 1046,-179.5 1046,-179.5 1040,-179.5 1034,-173.5 1034,-167.5 1034,-167.5 1034,-123.5 1034,-123.5 1034,-117.5 1040,-111.5 1046,-111.5 1046,-111.5 1132,-111.5 1132,-111.5 1138,-111.5 1144,-117.5 1144,-123.5 1144,-123.5 1144,-167.5 1144,-167.5 1144,-173.5 1138,-179.5 1132,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1049\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"1044\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 136</text>\n",
       "<text text-anchor=\"start\" x=\"1042\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 136]</text>\n",
       "<text text-anchor=\"start\" x=\"1061\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = B</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1009.98,-222.91C1022.08,-211.21 1035.27,-198.46 1047.34,-186.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.94,-189.13 1054.7,-179.67 1045.08,-184.1 1049.94,-189.13\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x217f7160d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(dt_clf, \n",
    "                                out_file=None,\n",
    "                                feature_names=data.columns,\n",
    "                                class_names= target.unique(),\n",
    "                                filled=True, \n",
    "                                rounded=True,\n",
    "                                special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "> Two impurity measures can be used for decision trees in *scikit-learn*: *Information Gain* or *Entropy* and the *Gini index* (more details on these measures [here](https://en.wikipedia.org/wiki/Decision_Learning#)).\n",
    ">\n",
    "> In summary, entropy is 0 if all the samples of a node belong to the same class, and entropy is maximum if we have a uniform class distribution (i.e. when all the node classes have an equal probability).\n",
    ">\n",
    "> Gini index is similar to entropy, but the choice of the criterion used sometimes gives different classifications.\n",
    "\n",
    "* **(h)** Create a classifier **`dt_clf_gini`**, having for parameters:`riterion ='gini'`, `max_Depth=4` and` random_state=321'.\n",
    "\n",
    "\n",
    "* **(i)** Train the new model on the training set (**`x_train`** and **` y_train`**).\n",
    "\n",
    "\n",
    "* **(j)** Save the predictions of the model on **`x_test`** in **`y_pred`**.\n",
    "\n",
    "\n",
    "* **(k)** Show the corresponding confusion matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Class</th>\n",
       "      <th>B</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Class   B   M\n",
       "Actual Class           \n",
       "B                72   1\n",
       "M                 4  37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=321)\n",
    "dt_clf_gini.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_clf_gini.predict(X_test)\n",
    "cm = pd.crosstab(y_test, y_pred, rownames=['Actual Class'], colnames=['Predicted Class'])\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "* **(l)** Display, as in the previous model, the eight most **important** variables, along with their respective importance scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_worst</th>\n",
       "      <td>0.718582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points_worst</th>\n",
       "      <td>0.112821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_worst</th>\n",
       "      <td>0.048798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.033920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.030343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_worst</th>\n",
       "      <td>0.016458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.011231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_se</th>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Gini-importance\n",
       "radius_worst                 0.718582\n",
       "concave points_worst         0.112821\n",
       "texture_worst                0.048798\n",
       "concavity_mean               0.033920\n",
       "texture_mean                 0.030343\n",
       "area_worst                   0.016458\n",
       "smoothness_mean              0.011231\n",
       "texture_se                   0.009682"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = {}\n",
    "for feature, importance in zip(data.columns, dt_clf_gini.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "\n",
    "#Affixing of the 8 most important variables\n",
    "importances.sort_values(by='Gini-importance', ascending=False).head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "> The trees corresponding to the classifiers created can be displayed thanks to the function [`plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html).\n",
    "> Visualizing the tree is important for understanding how the model works and how it can potentially be improved (for example, by removing a variable that promotes overfitting).\n",
    ">\n",
    "> Here are the trees corresponding to the two models created:\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">4. Tree with the \"entropy\" criterion</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "><img  src=\"https://datascientest.fr/train/assets/entropytree.jpg\" style = \"height:500px\" />\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">5. Tree with the \"Gini\" criterion</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "><img  src=\"https://datascientest.fr/train/assets/ginitree.jpg\" style = \"height:500px\" />\n",
    ">\n",
    ">The first summit is the root of the tree. It is located on the first level. The tree contains the frequency distribution of the variable to be predicted `diagnosis`. 455 variables are used for the construction of the tree.<br>\n",
    "> In both cases, the variable `radius_worst` is the first variable used. It is called the segmentation variable. It therefore produces two wire knots, and so on, until a pure class is obtained, where until the number of nodes created reaches the maximum authorized number (here equal to 4).\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<h3 style = \"text-align:center\">Synthesis</h3> \n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    ">Decision-based algorithms make it possible to respond simply and quickly to a classification problem. They do not formulate hypotheses about data and are not affected by the problems of scales for measuring variables.<br>\n",
    "> They can manage both digital and categorical variables, and are easily interpreted.\n",
    ">\n",
    ">However, decision -making models can be quite unstable: they are sensitive to (even fairly low) variations in the learning set in terms of samples or variables considered.<br>\n",
    "> Sometimes, decision trees are also very complex, and badly generalize the learning set (*overfitting*). Additional pruning procedures are used to get around this problem, certain approaches such as **random forests** allow you to get rid of it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
