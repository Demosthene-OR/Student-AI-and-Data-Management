{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" width=\"400\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><H1> Introduction au Machine Learning avec Scikit-learn </H1></center> \n",
    "<center><H2> Partie II : Mod\u00e8les simples de classification </H2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "> Pour cette seconde partie d'introduction au module `scikit-learn`, nous allons nous int\u00e9resser au deuxi\u00e8me type de probl\u00e8me en Machine Learning : le probl\u00e8me de **classification**.\n",
    "> \n",
    "> L'objectif de cette introduction est :\n",
    ">> * D'introduire le probl\u00e8me de classification.\n",
    ">>\n",
    ">>\n",
    ">> * D'apprendre \u00e0 utiliser le module `scikit-learn` pour construire un mod\u00e8le de classification, aussi appel\u00e9 \u00abclassifieur\u00bb.\n",
    ">>\n",
    ">>\n",
    ">> * D'introduire des m\u00e9triques utiles \u00e0 l'\u00e9valuation des performances du mod\u00e8le.\n",
    "\n",
    "## Introduction \u00e0 la classification\n",
    "\n",
    "### Objectif de la classification\n",
    "\n",
    "> En Apprentissage supervis\u00e9, l'objectif est de pr\u00e9dire la valeur d'une variable cible \u00e0 partir de variables explicatives.\n",
    ">> * Dans un probl\u00e8me de **r\u00e9gression**, la variable cible prend des **valeurs continues**. Ces valeurs sont num\u00e9riques : prix d'une maison, quantit\u00e9 d'oxyg\u00e8ne dans l'air d'une ville, etc... <br> La variable cible peut donc prendre une **infinit\u00e9 de valeurs**.\n",
    ">>\n",
    ">>\n",
    ">> * Dans un probl\u00e8me de **classification**, la variable cible prend des **valeurs discr\u00e8tes**. Ces valeurs peuvent \u00eatre num\u00e9riques ou litt\u00e9rales mais dans les deux cas, la variable cible prend un **nombre fini de valeurs**. <br>\n",
    "> Les diff\u00e9rentes valeurs prises par la variable cible sont ce qu'on appelle des **classes**. \n",
    ">\n",
    "> **L'objectif de la classification consiste donc \u00e0 pr\u00e9dire la classe d'une observation \u00e0 partir de ses variables explicatives.**\n",
    "\n",
    "### Un exemple de classification\n",
    "\n",
    "> Prenons un exemple de classification **binaire**, autrement dit o\u00f9 il y a **deux** classes. <br>\n",
    "> Nous cherchons \u00e0 d\u00e9terminer si l'eau d'un ruisseau est potable ou non en fonction de sa concentration en substances toxiques et de sa teneur en sels min\u00e9raux. \n",
    ">\n",
    "> Les deux classes sont donc **'potable'** et **'non potable'**. \n",
    ">\n",
    "> <br>\n",
    "> <img src = 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_classification_binaire.png' style = \"height:400px\">\n",
    "> <br>\n",
    ">\n",
    "> Sur la figure ci-dessus, chaque point repr\u00e9sente un ruisseau dont la position sur le plan est d\u00e9finie par ses valeurs de concentration en substances toxiques et de teneur en sels min\u00e9raux. \n",
    "> \n",
    "> L'objectif sera de construire un **mod\u00e8le capable d'attribuer une des deux classes** ('potable'/'non potable') \u00e0 un ruisseau dont on ne connait que ces deux variables.\n",
    ">\n",
    "> La figure ci-dessus sugg\u00e8re l'existence de deux zones permettant de classifier les ruisseaux facilement :\n",
    ">> * Une zone o\u00f9 les ruisseaux sont potables (en haut \u00e0 gauche).\n",
    ">>\n",
    ">>\n",
    ">> * Une zone o\u00f9 les ruisseaux sont non potables (en bas \u00e0 droite).\n",
    ">\n",
    "> Nous aimerions cr\u00e9er un mod\u00e8le capable de **s\u00e9parer le jeu de donn\u00e9es en deux parties** correspondant \u00e0 ces zones. \n",
    ">\n",
    "> Une technique simple serait de s\u00e9parer les deux zones \u00e0 **l'aide d'une ligne**.\n",
    "\n",
    "* **(a)** Ex\u00e9cuter la cellule suivante pour afficher la figure interactive.\n",
    "> * Les points **oranges** sont les ruisseaux **potables** et les points **bleus** sont les ruisseaux **non-potables**.\n",
    "> \n",
    "> * La **fl\u00e8che rouge** correspond \u00e0 un **vecteur** d\u00e9fini par $w = (w_1, w_2)$. La ligne rouge correspond au plan orthogonal (i.e. perpendiculaire) \u00e0 $w$. Vous pouvez modifier les coordonn\u00e9es du vecteur $w$ de deux fa\u00e7ons :\n",
    ">> * En faisant d\u00e9filer les curseurs `w_1` et `w_2`.\n",
    ">>\n",
    ">>\n",
    ">> * En cliquant sur les valeurs \u00e0 droite des curseurs puis en ins\u00e9rant directement la valeur souhait\u00e9e.\n",
    "\n",
    "\n",
    "* **(b)** Essayer de trouver un vecteur $w$ tel que **le plan orthogonal \u00e0 $w$ s\u00e9pare parfaitement les deux classes de ruisseau**.\n",
    "\n",
    "\n",
    "* **(c)** Une solution possible est donn\u00e9e par le vecteur $w = (-1.47, 0.84)$. Est-ce que le vecteur $w = (1.47, -0.84)$ donne aussi une solution ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from classification_widgets import linear_classification\n",
    "\n",
    "linear_classification()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> La classification que nous venons de faire est de type **lin\u00e9aire**, c'est-\u00e0-dire que nous avons utilis\u00e9 un plan lin\u00e9aire pour s\u00e9parer nos classes.\n",
    ">\n",
    "> Ainsi, l'objectif des mod\u00e8les de classification lin\u00e9aires est de trouver le vecteur $w$ permettant de s\u00e9parer au mieux les diff\u00e9rentes classes. <br>\n",
    "> Chaque mod\u00e8le de type lin\u00e9aire dispose de sa propre technique pour trouver ce vecteur.\n",
    ">\n",
    "> Il existe aussi des mod\u00e8les de classification non-lin\u00e9aires, que nous verrons plus tard.\n",
    ">\n",
    "> <br>\n",
    "> <img src = 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_classification_lin_non_lin.png' style = \"height:400px\">\n",
    "\n",
    "## 1. Utilisation de `scikit-learn` pour la classification\n",
    "\n",
    "> Nous allons maintenant introduire les principaux outils du module `scikit-learn` essentiels \u00e0 la r\u00e9solution d'un probl\u00e8me de classification.\n",
    ">\n",
    "> Dans cet exercice, nous utiliserons le jeu de donn\u00e9es [Congressional Voting Records](https://archive.ics.uci.edu/ml/datasets/congressional+voting+records) qui contient un nombre de votes faits par les membres du Congr\u00e8s de la Chambre des Repr\u00e9sentants des \u00c9tats-Unis.\n",
    ">\n",
    "> L'objectif de notre probl\u00e8me de classification sera de **pr\u00e9dire le parti politique** (\"d\u00e9mocrate\" ou \"r\u00e9publicain\") des membres de la Chambre des Repr\u00e9sentants en fonction de leurs votes sur des sujets comme l'\u00e9ducation, la sant\u00e9, le budget, etc... \n",
    ">\n",
    "> Les variables explicatives seront donc les votes sur diff\u00e9rents sujets et la variable cible sera le parti politique \"d\u00e9mocrate\" ou \"r\u00e9publicain\".\n",
    ">\n",
    "> Pour r\u00e9soudre ce probl\u00e8me nous allons utiliser un mod\u00e8le de classification lin\u00e9aire : la **R\u00e9gression Logistique**.\n",
    "\n",
    "\n",
    "### Pr\u00e9paration des donn\u00e9es\n",
    "\n",
    "* **(a)** Ex\u00e9cuter la cellule suivante pour importer les modules `pandas` et `numpy` n\u00e9cessaires \u00e0 la suite de l'exercice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "* **(b)** Charger les donn\u00e9es contenues dans le fichier `'votes.csv'` dans un `DataFrame` nomm\u00e9 `votes`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "votes = pd.read_csv('votes.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "Afin de visualiser bri\u00e8vement nos donn\u00e9es :\n",
    "\n",
    "* **(c)** Afficher le nombre de lignes et de colonnes de `votes`.\n",
    "\n",
    "\n",
    "* **(d)** Afficher un aper\u00e7u des 20 premi\u00e8res lignes de `votes`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Dimensions du DataFrame\n",
    "print('Le DataFrame poss\u00e8de', votes.shape[0], 'lignes et', votes.shape[1], 'colonnes.')\n",
    "\n",
    "# Affichage des 20 premi\u00e8res lignes\n",
    "votes.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> * La premi\u00e8re colonne **`\"party\"`** contient le nom du **parti politique** auquel chaque membre du Congr\u00e8s de la Chambre des Repr\u00e9sentants appartient.  \n",
    ">\n",
    ">\n",
    "> * Les **16 colonnes** suivantes contiennent les votes de chaque membre du Congr\u00e8s sur des propositions de lois : \n",
    ">> * `'y'` indique que l'\u00e9lu a vot\u00e9 **pour** la proposition de loi.\n",
    ">>\n",
    ">>\n",
    ">> * `'n'` indique que l'\u00e9lu a vot\u00e9 **contre** la proposition de loi.\n",
    ">\n",
    "> Afin d'utiliser les donn\u00e9es dans un mod\u00e8le de classification, il est n\u00e9cessaire de transformer ces colonnes en valeurs **num\u00e9riques** binaires, autrement dit soit 0 soit 1.\n",
    "\n",
    "* **(e)** Pour chacune des colonnes 1 \u00e0 16 (la colonne 0 \u00e9tant notre variable cible), remplacer les valeurs `'y'` par 1 et `'n'` par 0. Pour cela, on peut s'aider de la m\u00e9thode **`replace`** de la classe `DataFrame`.\n",
    "\n",
    "\n",
    "* **(f)** Afficher les 10 premi\u00e8res lignes du `DataFrame` modifi\u00e9.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Remplacement des valeurs\n",
    "votes = votes.replace(('y', 'n'), (1, 0))\n",
    "\n",
    "# Affichage du DataFrame\n",
    "votes.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "* **(g)** Dans un `DataFrame` nomm\u00e9 `X`, stocker les variables **explicatives** du jeu de donn\u00e9es (toutes les colonnes sauf `'party'`). Pour cela, vous pourrez vous aider de la m\u00e9thode **`drop`** d'un `DataFrame`.\n",
    "\n",
    "\n",
    "* **(h)** Dans une `Series` nomm\u00e9 `y`, stocker la **variable cible** (`'party'`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# S\u00e9paration des donn\u00e9es\n",
    "\n",
    "X = votes.drop(['party'], axis = 1)\n",
    "y = votes['party']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Comme pour la r\u00e9gression, nous allons devoir s\u00e9parer le jeu de donn\u00e9es en 2 parties : un jeu **d'entra\u00eenement** et un jeu de **test**. Pour rappel :\n",
    ">> * Le jeu d'entra\u00eenement sert \u00e0 **entra\u00eener le mod\u00e8le** de classification, c'est-\u00e0-dire trouver les param\u00e8tres du mod\u00e8le qui s\u00e9parent au mieux les classes.\n",
    ">>\n",
    ">>\n",
    ">> * Le jeu de test sert \u00e0 **\u00e9valuer** le mod\u00e8le sur des donn\u00e9es qu'il n'a jamais vues. Cette \u00e9valuation nous permettra de juger sur la capacit\u00e9 \u00e0 **g\u00e9n\u00e9raliser** du mod\u00e8le.\n",
    "\n",
    "* **(i)** Importer la fonction `train_test_split` du sous module `sklearn.model_selection`. On rappelle que cette fonction s'utilise ainsi :\n",
    ">```python\n",
    ">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    ">```\n",
    "\n",
    "\n",
    "* **(j)** S\u00e9parer les donn\u00e9es en un jeu d'entra\u00eenement `(X_train, y_train)` et un jeu de test `(X_test, y_test)` en gardant 20% des donn\u00e9es pour l'\u00e9chantillon de test.\n",
    "> Pour \u00e9liminer l'al\u00e9a de la fonction `train_test_split`, vous pouvez utiliser le param\u00e8tre `random_state` avec une valeur enti\u00e8re (par exemple `random_state = 2`). <br>\n",
    "> Ainsi, \u00e0 chaque fois que vous utiliserez la fonction avec l'argument `random_state = 2`, les jeux de donn\u00e9es produits seront les m\u00eames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> Le mod\u00e8le de r\u00e9gression logistique est \u00e9troitement li\u00e9 au mod\u00e8le de **r\u00e9gression lin\u00e9aire** vu dans le pr\u00e9c\u00e9dent notebook. \n",
    ">\n",
    "> Il ne faut pas les **confondre** puisqu'ils ne r\u00e9solvent pas les m\u00eames types de probl\u00e8mes :\n",
    ">> * La r\u00e9gression **logistique** est utilis\u00e9e pour la classification (pr\u00e9dire des classes).\n",
    ">>\n",
    ">>\n",
    ">> * La r\u00e9gression **lin\u00e9aire** est utilis\u00e9e pour la r\u00e9gression (pr\u00e9dire une variable quantitative).\n",
    ">\n",
    "> Le mod\u00e8le de r\u00e9gression lin\u00e9aire \u00e9tait d\u00e9fini par la formule suivante :\n",
    "> $$ y \\approx \\beta_0 + \\sum_{j=1}^p \\beta_j x_j $$\n",
    ">\n",
    "> La r\u00e9gression logistique n'estime plus $y$ directement mais la **probabilit\u00e9** que $y$ soit \u00e9gal \u00e0 0 ou 1. <br>\n",
    "> Ainsi, le mod\u00e8le est d\u00e9fini par la formule :\n",
    "> $$P(y = 1) = f(\\beta_0 + \\sum_{j=1}^p \\beta_j x_j)$$\n",
    ">\n",
    "> O\u00f9 $$f(x) = \\frac{1}{1 + e^{-x}}$$\n",
    ">\n",
    "> La fonction $f$, souvent appel\u00e9e **sigmo\u00efde** ou **fonction logistique**, permet de transformer la combinaison lin\u00e9aire $\\beta_0 + \\sum_{j=1}^p \\beta_j x_j$ en une valeur comprise entre 0 et 1 que l'on pourra interpr\u00e9ter comme une **probabilit\u00e9** :\n",
    ">> * Si $\\beta_0 + \\sum_{j=1}^p \\beta_j x_j$ est positif, alors $P(y = 1) \\gt 0.5$, donc la classe pr\u00e9dite de l'observation sera 1.\n",
    ">>\n",
    ">>\n",
    ">> * Si $\\beta_0 + \\sum_{j=1}^p \\beta_j x_j$ est n\u00e9gatif, alors $P(y = 1) \\lt 0.5$, c'est-\u00e0-dire que $P(y = 0) \\gt 0.5$, donc la classe pr\u00e9dite de l'observation sera 0.\n",
    "\n",
    "* **(k)** Importer la classe `LogisticRegression` du sous-module `linear_model` de `scikit-learn`.\n",
    "\n",
    "\n",
    "* **(l)** Instancier un mod\u00e8le `LogisticRegression` nomm\u00e9 **`logreg`** sans pr\u00e9ciser d'arguments du constructeur.\n",
    "\n",
    "\n",
    "* **(m)** Entra\u00eener le mod\u00e8le sur le jeu de donn\u00e9es d'entra\u00eenement gr\u00e2ce \u00e0 la m\u00e9thode `fit` de la classe `LogisticRegression`.\n",
    "\n",
    "\n",
    "* **(n)** Effectuer une pr\u00e9diction sur les donn\u00e9es de **test**. Stocker ces pr\u00e9dictions dans **`y_pred_test_logreg`** et afficher les 10 premi\u00e8res pr\u00e9dictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Importation de la classe LogisticRegression sous-module linear_model de sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciation du mod\u00e8le\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Entra\u00eenement du mod\u00e8le sur le jeu d'entra\u00eenement\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Pr\u00e9diction sur les donn\u00e9es de test\n",
    "y_pred_test_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Affichage des 10 premi\u00e8res pr\u00e9dictions\n",
    "print(y_pred_test_logreg[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## 2. Evaluer la performance d'un mod\u00e8le de classification\n",
    "\n",
    "> Il existe diff\u00e9rentes m\u00e9triques pour \u00e9valuer les performances de mod\u00e8les de classification comme :\n",
    ">> * L'**accuracy**.\n",
    ">> \n",
    ">>\n",
    ">> * La **pr\u00e9cision et le rappel** (*precision* et *recall* en anglais).\n",
    ">\n",
    "> \n",
    "> Chaque m\u00e9trique \u00e9value la performance du mod\u00e8le avec une approche diff\u00e9rente.\n",
    ">\n",
    "> Afin d'expliquer ces notions, nous allons introduire 4 termes tr\u00e8s importants. \n",
    ">\n",
    "> **Arbitrairement**, nous allons choisir que la classe **'republican' sera la classe positive** (1) et **'democrat' sera la classe n\u00e9gative** (0).\n",
    ">\n",
    "> Ainsi, nous appellerons :\n",
    ">> * **Vrai positif (VP)** une observation class\u00e9e **positive** ('republican') par le mod\u00e8le et qui est effectivement **positive** ('republican').\n",
    ">>\n",
    ">>\n",
    ">> * **Faux positif (FP)** une observation class\u00e9e **positive** ('republican') par le mod\u00e8le mais qui \u00e9tait en r\u00e9alit\u00e9 **n\u00e9gative** ('democrat').\n",
    ">>\n",
    ">>\n",
    ">> * **Vrai n\u00e9gatif (VN)** une observation class\u00e9e **n\u00e9gative** ('democrat') par le mod\u00e8le et qui est effectivement **n\u00e9gative** ('democrat').\n",
    ">>\n",
    ">>\n",
    ">> * **Faux n\u00e9gatif (FN)** une observation class\u00e9e **n\u00e9gative** ('democrat') par le mod\u00e8le mais qui \u00e9tait en r\u00e9alit\u00e9 **positive** ('republican').\n",
    ">\n",
    "> <br>\n",
    "> <img src = \"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_positif_negatif.png\" style = \"height:300px'\">\n",
    "> <br>\n",
    ">\n",
    "> L'**accuracy** est la m\u00e9trique la plus couramment utilis\u00e9e pour \u00e9valuer un mod\u00e8le. <br>\n",
    "> Elle correspond simplement au taux de pr\u00e9dictions **correctes** effectu\u00e9es par le mod\u00e8le.\n",
    ">\n",
    "> On suppose que l'on dispose de $n$ observations. <br>\n",
    "> On note $\\mathrm{VP}$ le nombre de Vrais Positifs et $\\mathrm{VN}$ le nombre de Vrais N\u00e9gatifs.<br>\n",
    "> L'accuracy est alors donn\u00e9e par :\n",
    "> $$\\mathrm{accuracy} = \\frac{\\mathrm{VP} + \\mathrm{VN}}{n}$$\n",
    "> \n",
    "> La **pr\u00e9cision** est une m\u00e9trique qui r\u00e9pond \u00e0 la question : **Parmi toutes les pr\u00e9dictions positives du mod\u00e8le, combien sont de vrais positifs ?**\n",
    ">\n",
    "> Si on note $\\mathrm{FP}$ le nombre de Faux Positifs du mod\u00e8le, alors la pr\u00e9cision est donn\u00e9e par :\n",
    "> $$\\mathrm{precision} = \\frac{\\mathrm{VP}}{\\mathrm{VP} + \\mathrm{FP}}$$\n",
    ">\n",
    "> Un score de pr\u00e9cision \u00e9lev\u00e9 nous informe que le mod\u00e8le ne classe pas aveugl\u00e9ment toutes les observations comme positives.\n",
    "> \n",
    "> Le **rappel** est une m\u00e9trique qui quantifie la proportion d'observations r\u00e9ellement positives qui ont \u00e9t\u00e9 correctement classifi\u00e9es positives par le mod\u00e8le.\n",
    ">\n",
    "> Si on note $\\mathrm{FN}$ le nombre de Faux N\u00e9gatifs, alors le rappel est donn\u00e9 par :\n",
    "> $$\\mathrm{rappel} = \\frac{\\mathrm{VP}}{\\mathrm{VP} + \\mathrm{FN}}$$\n",
    ">\n",
    "> Un score de rappel \u00e9lev\u00e9 nous informe que le mod\u00e8le est capable de bien d\u00e9tecter les observations r\u00e9ellement positives.\n",
    ">\n",
    "> La **matrice de confusion** compte pour un jeu de donn\u00e9es les valeurs de VP, VN, FP et FN, ce qui nous permet de calculer les trois m\u00e9triques pr\u00e9c\u00e9dentes :\n",
    ">\n",
    "> $$\n",
    "\\mathrm{Confusion Matrix} = \\begin{bmatrix}\n",
    "                                    \\mathrm{VN} & \\mathrm{FP} \\\\\n",
    "                                    \\mathrm{FN} & \\mathrm{VP}\n",
    "                                \\end{bmatrix}\n",
    " $$\n",
    ">\n",
    "> La fonction **`confusion_matrix`** du sous-module `sklearn.metrics` permet de g\u00e9n\u00e9rer la matrice de confusion \u00e0 partir des **pr\u00e9dictions** d'un mod\u00e8le :\n",
    ">\n",
    "> ```python\n",
    "> confusion_matrix(y_true, y_pred)\n",
    ">\n",
    "> ```\n",
    ">\n",
    ">> * **`y_true`** contient les **vraies** valeurs de y.\n",
    ">>\n",
    ">>\n",
    ">> * **`y_pred`** contient les valeurs **pr\u00e9dites** par le mod\u00e8le.\n",
    ">\n",
    "> L'affichage de la matrice de confusion peut se faire aussi avec la fonction **`pd.crosstab`** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "* **(a)** Importer les fonctions **`accuracy_score`**, **`precision_score`** et **`recall_score`** du sous-module `sklearn.metrics`.\n",
    "\n",
    "\n",
    "* **(b)** Afficher la matrice de confusion des pr\u00e9dictions du mod\u00e8le **`logreg`** \u00e0 l'aide de **`pd.crosstab`**.\n",
    "\n",
    "\n",
    "* **(c)** Calculer l'accuracy, la pr\u00e9cision et le rappel des pr\u00e9dictions du mod\u00e8le **`logreg`**. Pour utiliser les m\u00e9triques `precision_score` et `recall_score`, il faudra renseigner l'argument **`pos_label = 'republican'`** afin de pr\u00e9ciser que la classe `'republican'` est la classe positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Ins\u00e9rez votre code ici\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calcul et affichage de la matrice de confusion\n",
    "print(pd.crosstab(y_test, y_pred_test_logreg, rownames=['Realit\u00e9'], colnames=['Pr\u00e9diction']))\n",
    "\n",
    "# Calcul de l'accuracy, precision et rappel\n",
    "print(\"\\nLogReg Accuracy:\", accuracy_score(y_test, y_pred_test_logreg))\n",
    "\n",
    "print(\"\\nLogReg Pr\u00e9cision:\", precision_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n",
    "\n",
    "print(\"\\nLogReg Rappel:\", recall_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "# Recap\n",
    "\n",
    "> Scikit-learn propose de nombreux mod\u00e8les de classification comme **`LogisticRegression`**.\n",
    ">\n",
    "> L'utilisation de ces mod\u00e8les se fait de la m\u00eame fa\u00e7on pour **tous** les mod\u00e8les de scikit-learn :\n",
    ">> * **Instanciation** du mod\u00e8le.\n",
    ">>\n",
    ">> \n",
    ">> * **Entra\u00eenement** du mod\u00e8le : **`model.fit(X_train, y_train)`**.\n",
    ">>\n",
    ">>\n",
    ">> * **Pr\u00e9diction** : **`model.predict(X_test)`**.\n",
    ">\n",
    "> La pr\u00e9diction sur le jeu de test nous permet d'**\u00e9valuer** la performance du mod\u00e8le gr\u00e2ce \u00e0 des **m\u00e9triques** adapt\u00e9es.\n",
    ">\n",
    "> Les m\u00e9triques que nous avons vues s'utilisent pour la classification **binaire** et se calculent gr\u00e2ce \u00e0 4 valeurs :\n",
    ">> * Vrais Positifs :  Pr\u00e9diction = **+** | R\u00e9alit\u00e9 = **+**\n",
    ">>\n",
    ">>\n",
    ">> * Vrais N\u00e9gatifs : Pr\u00e9diction = **-** | R\u00e9alit\u00e9 = **-**\n",
    ">>\n",
    ">>\n",
    ">> * Faux Positifs :  Pr\u00e9diction = **+** | R\u00e9alit\u00e9 = **-**\n",
    ">>\n",
    ">>\n",
    ">> * Faux N\u00e9gatifs :  Pr\u00e9diction = **-** | R\u00e9alit\u00e9 = **+**\n",
    ">\n",
    "> Toutes ces valeurs peuvent se calculer \u00e0 l'aide de la **matrice de confusion** g\u00e9n\u00e9r\u00e9e par la fonction **`confusion_matrix`** du sous-module `sklearn.metrics` ou par la fonction **`pd.crosstab`**.\n",
    "> \n",
    "> Gr\u00e2ce \u00e0 ces valeurs, nous pouvons calculer des m\u00e9triques comme :\n",
    ">> * L'**accuracy** : La proportion d'observations correctement classifi\u00e9es.\n",
    ">>\n",
    ">>\n",
    ">> * La **pr\u00e9cision** : La proportion de vrais positifs parmi toutes les pr\u00e9dictions positives du mod\u00e8le.\n",
    ">>\n",
    ">>\n",
    ">> * Le **rappel** : La proportion d'observations r\u00e9ellement positives qui ont \u00e9t\u00e9 correctement classifi\u00e9es positives par le mod\u00e8le.\n",
    ">\n",
    "> Toutes ces m\u00e9triques peuvent s'obtenir \u00e0 l'aide de la fonction **`classification_report`** du sous-module **`sklearn.metrics`**.\n",
    ">\n",
    "# Conclusion et ressources\n",
    "\n",
    "> Ce module a permis de pr\u00e9senter le langage de programmation Python et d'introduire ses principales librairies tr\u00e8s utiles dans la suite (Numpy, Pandas, scikit-learn). La librairie Pandas permet notamment d'obtenir des donn\u00e9es sous forme de dataframes facilement manipulables.\n",
    ">\n",
    "> **Si vous voulez d\u00e9couvrir des m\u00e9thodes un peu plus pouss\u00e9es et dans la continuit\u00e9 de ce module, vous pouvez vous tourner vers le module \"105 Data Quality\".**\n",
    ">\n",
    "> **Si vous voulez appliquer les m\u00e9thodes pr\u00e9sent\u00e9es \u00e0 d'autres dataframes, vous pouvez le faire avec le module \"Bac \u00e0 sable\". Ce module est constitu\u00e9 d'un notebook vierge dans lequel des donn\u00e9es sont disponibles et sur lequel vous pouvez coder librement.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}