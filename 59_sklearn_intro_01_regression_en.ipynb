{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Demosthene-OR/Student-AI-and-Data-Management/blob/main/59_sklearn_intro_01_regression_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "<img src=\"https://prof.totalenergies.com/wp-content/uploads/2024/09/TotalEnergies_TPA_picto_DegradeRouge_RVB-1024x1024.png\" height=\"150\" width=\"150\">\n",
    "\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1>Introduction to machine learning with Scikit-Learn</h1></center>\n",
    "<center><h2>Linear regression</h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "> This notebook introduces the concepts of machine learning and more particularly of linear regression, in order to show how Python is a programming language adapted to automatic learning issues. All these concepts will be presented in more detail and put into practice in the modules dedicated to machine learning.\n",
    ">\n",
    "> Machine learning is a sub-domain of artificial intelligence, which gives the computer capacity to learn to automatically do tasks from data. When the task to be performed is the prediction of a variable, we are talking about supervised learning.\n",
    ">\n",
    "> Linear regression is one of the first predictive models of supervised learning to have been studied. This model predicts a quantitative variable. It is today the most popular model for practical applications thanks to its simplicity.\n",
    ">\n",
    "> In the lineaire regression model, we have the quantitative variable to predict (called target variable) and explanatory variables allowing prediction.\n",
    "\n",
    "### Univariated linear regression\n",
    "\n",
    ">In the univaried linear model, we have two variables, $ y $ called target variable or *target *and $ x $ called variable *explanatory *.<br>\n",
    "> Linear regression consists in modeling the link between these two variables by an affine function. Thus, the formula of the univaried linear model is given by:\n",
    "> $$ y \\ Approx \\ beta_1 x + \\ beta_0 $$\n",
    "> Where:\n",
    ">> * $ y $ is the variable we want to predict.\n",
    ">>\n",
    ">>\n",
    ">> * $ x $ is the explanatory variable.\n",
    ">>\n",
    ">>\n",
    ">> *$ \\ beta_1 $ and $ \\ beta_0 $ are the parameters of the affine function. $ \\ beta_1 $ will define its **slope** and $ \\ beta_0 $ will define its order originally (also called **biases**).\n",
    ">\n",
    "> **The goal of linear regression is to estimate the best parameters $ \\ beta_0 $ and $ \\ beta_1 $ to predict the variable $ y $ from a given value of $ x $**.\n",
    ">\n",
    "> To have an intuition of the univariate linear regression, let's look at the interactive example below.\n",
    "\n",
    "*** (A)** Execute the following cell to display the interactive figure. In this figure, we have simulated a dataset.\n",
    "\n",
    "\n",
    "*** (B)** Try to find using the tab of the tab `Regression 'the parameters $ \\ BETA_0 $ and $ \\ BETA_1 $ which are best closer to all points in the data set.\n",
    "\n",
    "\n",
    "*** (C)** What is the effect of each parameters on the regression function?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653f9ef47e1e48bfb59bcdb8d44acfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='beta', max=2.0, min=-2.0), FloatSlider(value=1.5, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2efb503ebba4e25afeb7a748b5e1d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(scale=LinearScale()), Axis(orientation='vertical', scale=LinearScale())], fig_margin={'top':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/Demosthene-OR/Student-AI-and-Data-Management/main/widgets.py\n",
    "from widgets import regression_widget\n",
    "\n",
    "regression_widget()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Multiple linear regression\n",
    "\n",
    "> Multiple linear regression consists in modeling the link between a target variable $ y $ and **several explanatory variables** $ x_1 $, $ x_2 $, ..., $ x_p $, often called*features*in English:\n",
    "> $$\n",
    "\\ Begin {align}\n",
    "Y & \\ Approx β_0 + β_1 x_1 + β_2 x_2 + ⋯ + β_p x_p \\\\\n",
    "& \\ Approx β_0+ \\ sum_ {j = 1}^{p} β_j x_j\n",
    "\\ End {align}\n",
    "$$\n",
    ">\n",
    "> There is now $ P + $ 1 settings $ \\ beta_j $ to find.\n",
    "\n",
    "\n",
    "## Use of Scikit-Learn for linear regression\n",
    "\n",
    "> We will now learn how to use the library **`Scikit-Learn`** in order to solve a machine learning problem. We will see in particular how useful this bookstore is to prepare the data and then to set up models.\n",
    ">\n",
    "> We place ourselves as part of a project so the objective is to predict the **sale price of a car** according to its **characteristics**. The variable to be predicted is quantitative and we therefore face a regression problem.\n",
    "\n",
    "### Importing the dataset\n",
    "\n",
    "> The database that we will use in the suite contains many characteristics about different cars of 1985.\n",
    ">\n",
    "> By simplicity, only the digital variables have been kept and the lines including missing values ​​have been deleted.\n",
    "\n",
    "*** (a)** Import the module `pandas` under the alias` pd`.\n",
    "\n",
    "\n",
    "*** (b)** in a dataframe` named `df`, import the dataset` Automobiles.csv` using the function `Read_csv` de` pandas`. This file is in the same folder as the execution environment of this notebook.\n",
    "\n",
    "\n",
    "*** (C)** Show the first 5 lines of `DF` to verify that the import went well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"automobiles.csv\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> * The symboling variable corresponds to the degree of risk vis-à-vis the insurer (risk of accident, breakdown, etc.).\n",
    ">\n",
    ">\n",
    "> * The normalized_losses' variable is the average cost of vehicle insurance per year. This value is standardized compared to cars of the same type (SUV, utility, sports, etc.).\n",
    ">\n",
    ">\n",
    ">* The following 13 variables concern the technical characteristics of cars such as width, length, displacement of the engine, horses, etc.<br>\n",
    ">\n",
    ">\n",
    "> * The last variable `Price` corresponds to the sale price of the vehicle. This is the variable that we will seek to predict.\n",
    "\n",
    "\n",
    "### separation of explanatory variables from the target variable\n",
    "\n",
    "> We will now create two `Dataframes', one containing the explanatory variables and another containing the target variable` Price`.\n",
    "\n",
    "*** (d)** In a dataframe` named `X`, make a copy of the explanatory variables of our data game, that is to say all the variables **except**` Price`.\n",
    "\n",
    "\n",
    "*** (e)** in a series of `y ', make a copy of the target variable` Price`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Explanatory variables\n",
    "X = df.drop(['price'], axis = 1)\n",
    "\n",
    "# Target variable\n",
    "y = df['price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Data separation in training and testing\n",
    "\n",
    "> We will now separate our data game into two parts. A part of **Training** and part of **test**. This stage is **extremely** important in data science.\n",
    ">\n",
    "> Indeed, as their names indicate:\n",
    ">> * The training game is used to \"train\" the model, that is to say find the $ \\ beta_0 settings $, ..., $ \\ beta_p $ optimals for this dataset.\n",
    ">>\n",
    ">>\n",
    ">>*The test part is used to \"test\" the model drawn by evaluating its ability to **generalize** its predictions on data that it has never seen **.\n",
    ">\n",
    "> A very useful function for performing this operation is the function `train_test_split 'of the submodule` Model_selection` de **`SCIKIT-Learn`**.\n",
    "\n",
    "*** (f)** Execute the following cell to import the function `train_test_split`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> This function is used as follows:\n",
    ">\n",
    "> `` python\n",
    "X_Train, x_test, y_train, y_test = train_test_split (x, y, test_size = 0.2, random_state = 42)\n",
    "> `` `\n",
    ">\n",
    ">>*`X_Train` and` Y_Train 'are the explanatory and target variables of the **Training dataset**.\n",
    ">>\n",
    ">>\n",
    ">>*`x_test` and` y_test` are the explanatory and target variables of the **test dataset**.\n",
    ">>\n",
    ">>\n",
    ">>*The argument `test_size` corresponds to the **proportion** of the dataset that we want to keep for the test game. In the previous example, this proportion corresponds to 20% of the initial dataset.\n",
    ">>\n",
    ">>\n",
    ">> * The `random_state` argument makes it possible to ensure that the cutting of data can be reproduced. Indeed, the operation being random, 2 successive divisions will give in theory 2 different results. As long as the value of `random_state` is the same (regardless of this value), the result of the train_test_split function will remain the same.\n",
    "\n",
    "*** (g)** Using the function `train_test_st_split`, separate the database into a training game (` x_train`, y_train`) and a test part (`x_test`,` y_test`) so that the test part contains **15% of the initial data game**. Specify the parameter `random_state = 42`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Data separation into training (85%) and test game (15%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Creation of the regression model\n",
    "\n",
    "> To cause a linear regression model on this dataset, we will use the class **`Linearregression`** contained in the submodule` Linear_model 'of `Scikit-Learn'.\n",
    "\n",
    "*** (h)** Execute the following cell to import the class `linearregression '.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "> The Scikit-Lear 'API allows you to train and assess models very easily. All classes of Scikit-Learn models have the following two methods:\n",
    ">> **`Fit`**: leads the model to a dataset.\n",
    ">>\n",
    ">>\n",
    ">>*** `predict`**: performs a prediction from explanatory variables.\n",
    ">\n",
    "> Here is an example of using a model with Scikit-Learn:\n",
    "> \n",
    "> `` python\n",
    "># Instaniation of the model\n",
    "> Linreg = linearregression ()\n",
    ">    \n",
    "># Model training on the training game\n",
    "> Linreg.fit (x_train, y_train)\n",
    ">  \n",
    "># Prediction of the target variable for the test game test. These predictions are stored in Y_Pred\n",
    "> y_Pred = Linreg.Predict (x_test)\n",
    "> `` `\n",
    "\n",
    "*** (i)** Install a model `linearregression 'named **` lr'**.\n",
    "\n",
    "\n",
    "*** (J)** Train `lr 'on the training data game.\n",
    "\n",
    "\n",
    "*** (K)** Perform a prediction on training data. Store these predictions in `Y_Pred_Train`.\n",
    "\n",
    "\n",
    "*** (l)** Predict a prediction on test data. Store these predictions in `y_Pred_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "# Model instantiation\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Model training\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of the target variable for train datasets\n",
    "y_pred_train = lr.predict(X_train)\n",
    "\n",
    "# Prediction of the target variable for the testing game test\n",
    "y_pred_test = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Evaluation of model performance\n",
    "\n",
    "> In order to assess the **quality of the predictions of the model** obtained thanks to the parameters $ \\ beta_0 $, ..., $ \\ beta_j $, there are several metrics (or*metrics*in English) in the library `Scikit-Learn '.\n",
    ">\n",
    "> One of the most used metrics for regression is the **average quadratic error** (or*Mean Squared Error*in English) which exists under the name of `mean_squared_error;\n",
    ">\n",
    "> This function consists in calculating the average of the differences between **true values ​​** of the target variable and **predicted values ​​** thanks to the regression function. The average quadratic error is in fact only the average of these high distances in the square.\n",
    ">\n",
    "> The function `mean_squared_error 'of` scikit-learn` is used as follows:\n",
    ">\n",
    "> `` python\n",
    "mean_squared_error (y_true, y_pred)\n",
    "> `` `\n",
    "> Where:\n",
    ">> * `Y_True` corresponds to the true values ​​of the target variable.\n",
    ">>\n",
    ">>\n",
    ">> * `Y_Pred` corresponds to the values ​​predicted by our model.\n",
    "\n",
    "*** (o)** import the function **`mean_squared_error`** from the submodule` Sklearn.metrics`.\n",
    "\n",
    "\n",
    "*** (p)** Evaluate the quality of prediction of the model on **the training data**. Store the result in a variable named `MSE_TRAIN`.\n",
    "\n",
    "\n",
    "*** (q)** Evaluate the quality of prediction of the model on **test data**. Store the result in a variable named `mse_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculation of the MSE between the values ​​of the target variable of the train dataset and the prediction on x_train\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculation of the MSE between the values ​​of the target variable of the test game test and the prediction on x_test\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"MSE train lr:\", mse_train)\n",
    "print(\"MSE test lr:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "> The average quadratic error that you will find should be several million on test data, which can be difficult to interpret.\n",
    ">\n",
    "> This is why we will use another metric, the **Absolute Middle Error** (*Mean Absolute Error*in English) which directly calculates the differences in absolute value between the true values ​​of the target variable and the predicted values.\n",
    "\n",
    "*** (s)** import the function `mean_absolute_error 'from the submodule` Sklearn.metrics`.\n",
    "\n",
    "\n",
    "*** (t)** Evaluate the quality of prediction on test and training data using the average absolute error.\n",
    "\n",
    "\n",
    "*** (u)** From the `Dataframe`` Df`, calculate the average purchase price on all vehicles. Do the predictions of the model seem reliable to you?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "function": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculation of the MAE between the true values ​​of the target variable of the train and the prediction on x_train\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculation of the MAE between the true values ​​of the target variable of the test and the prediction on x_test\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"MAE train lr:\", mae_train)\n",
    "print(\"MAE test lr:\", mae_test)\n",
    "\n",
    "mean_price = df['price'].mean()\n",
    "\n",
    "print(\"\\nRelative error\", mae_test / mean_price)\n",
    "\n",
    "# The average error is around 14% of the average price, which is not optimal\n",
    "# But is still a good baseline to test more advanced models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## Conclusion and recap\n",
    "\n",
    "> In this notebook, we have introduced the resolution of a machine learning problem.\n",
    "> \n",
    "> The different stages that we have studied are the classic steps of any project:\n",
    ">\n",
    "> * Exploration of data with the pandas` bookstore\n",
    ">\n",
    "> * Preparation of data by separating the explanatory variables from the target variable\n",
    ">\n",
    "> * Separation of the dataset in two (a training game and a test game) using the function `train_test_split 'of the bookstore` Scikit-Learn'\n",
    ">\n",
    "> * Identification of the problem type: here a regression\n",
    ">\n",
    "> * Instantiation of a model like `linearregression 'with the bookstore` Scikit-Learn'\n",
    ">\n",
    "> * Model training on the training datasets using the Fit` method\n",
    ">\n",
    "> * Prediction on test data thanks to the predictory method\n",
    ">\n",
    "> * Evaluation of model performance by calculating the error between these predictions and the real values ​​of the target variable of test data. The evaluation for a regression model is easily done thanks to the functions `mean_squared_error 'or` mean_absolute_error' of the sub-module `Metrics` de Scikit-Learn.\n",
    ">\n",
    "> In the next notebook, we will perform the same steps but for the solving a classification machine learning problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "owner": "DataScientest"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
