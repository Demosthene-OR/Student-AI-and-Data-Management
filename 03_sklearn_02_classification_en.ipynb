{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" width=\"400\">\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><H1>Introduction to machine learning with Scikit-Learn</H1></center> \n",
        "<center><H2>Part II: Simple classification models</H2></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> For this second part of the introduction to the `Scikit-Learn` module, we will be interested in the second type of problem in the machine learning: the **classification problem**.\n",
        "> \n",
        "> The objective of this introduction is:\n",
        ">> * to introduce the classification problem.\n",
        ">>\n",
        ">>\n",
        ">> * To learn to use the `SCIKIT-LEARN` module to build a classification model, also called\" classifier \".\n",
        ">>\n",
        ">>\n",
        ">> * to introduce metrics useful for the evaluation of the model performance.\n",
        "\n",
        "## Introduction to classification\n",
        "\n",
        "### Objective of classification\n",
        "\n",
        "> In supervised learning, the objective is to predict the value of a target variable from explanatory variables.\n",
        ">>*In a problem of ** regression **, the target variable takes ** continuous values ​​**. These values ​​are digital: price of a house, quantity of oxygen in the air of a city, etc ...<br> La variable cible peut donc prendre une **infinité de valeurs**.\n",
        ">>\n",
        ">>\n",
        ">>*In a ** classification problem **, the target variable takes ** discreet values ​​**. These values ​​can be digital or literal but in both cases, the target variable takes a finished ** number of values ​​**.<br>\n",
        "> The different values ​​taken by the target variable are what are called **classes**.\n",
        ">\n",
        "> **The objective of the classification therefore consists in predicting the class of an observation from its explanatory variables.**\n",
        "\n",
        "### An example of classification\n",
        "\n",
        ">Take an example of classification ** binary **, in other words where there are ** two ** classes.<br>\n",
        "> We seek to determine whether the water of a stream is drinking or not depending on its concentration of toxic substances and its content of mineral salts.\n",
        ">\n",
        "> The two classes are therefore **'drinking'** and **'non potable'**.\n",
        ">\n",
        "><br>\n",
        "><img src = 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_classification_binaire.png' style = \"height:400px\">\n",
        "><br>\n",
        ">\n",
        "> In the above figure, each point represents a stream whose position on the plane is defined by its values ​​of concentration in toxic substances and content of mineral salts.\n",
        "> \n",
        "> The objective will be to build a **model capable of attributing one of the two classes** ('drinking'/'non -potable') to a stream of which we only know these two variables.\n",
        ">\n",
        "> The above figure suggests the existence of two zones to classify the streams easily:\n",
        ">> * An area where the streams are drinking (top left).\n",
        ">>\n",
        ">>\n",
        ">> * An area where the streams are non -potable (bottom right).\n",
        ">\n",
        "> We would like to create a model capable of **separate the database into two parts** corresponding to these areas.\n",
        ">\n",
        "> A simple technique would be to separate the two areas to **the help of a line**.\n",
        "\n",
        "*** (A)** Execute the following cell to display the interactive figure.\n",
        ">*The points **oranges** are the drinking **** streams** and the points **blue** are the **non-protest streams**.\n",
        "> \n",
        ">*The **red arrow** corresponds to a **vector** defined by $ w = (w_1, w_2) $. The red line corresponds to the orthogonal plane (i.e. perpendicular) to $ w $. You can change the vector contact details $ w $ in two ways:\n",
        ">> * scrolling the cursors `W_1 'and` W_2`.\n",
        ">>\n",
        ">>\n",
        ">> * by clicking on the values ​​to the right of the sliders then by directly inserting the desired value.\n",
        "\n",
        "\n",
        "*** (b)** Try to find a vector $ w $ such that **the orthogonal plan at $ w $ perfectly separates the two stream classes**.\n",
        "\n",
        "\n",
        "*** (C)** A possible solution is given by the vector $ w = (-1.47, 0.84) $. Does the vector $ w = (1.47, -0.84) also gives a solution?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "from classification_widgets import linear_classification\n",
        "\n",
        "linear_classification()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "> The classification we have just made is of the **linear** type, that is to say that we used a linear plan to separate our classes.\n",
        ">\n",
        ">Thus, the objective of the linear classification models is to find the vector $ W $ allowing to best separate the different classes.<br>\n",
        "> Each linear type model has its own technique to find this vector.\n",
        ">\n",
        "> There are also non-linear classification models, which we will see later.\n",
        ">\n",
        "><br>\n",
        "><img src = 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_classification_lin_non_lin.png' style = \"height:400px\">\n",
        "\n",
        "## 1. Using `scikit-lear 'for classification\n",
        "\n",
        "> We will now introduce the main tools of the `Scikit-learn` module essential to the resolution of a classification problem.\n",
        ">\n",
        "> In this exercise, we will use the dataset [Congressional Voting Records] (https://archive.ucs.uci.edu/ml/datasets/congressional+voing+records) which contains a number of votes made by members of the Congress of the Chamber of Representatives of the United States.\n",
        ">\n",
        "> The objective of our classification problem will be to **predict the political party** (\"democrat\" or \"republican\") of the members of the House of Representatives according to their votes on subjects such as education, health, budget, etc ...\n",
        ">\n",
        "> The explanatory variables will therefore be the votes on different subjects and the target variable will be the political party \"democrat\" or \"republican\".\n",
        ">\n",
        "> To solve this problem we will use a linear classification model: **Logistics regression**.\n",
        "\n",
        "\n",
        "### Data preparation\n",
        "\n",
        "*** (A)** Execute the following cell to import the modules `Pandas` and` Numpy` necessary following the exercise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "*** (b)** Load the data contained in the `'votes.csv'' file in a dataframe` named` votes`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "votes = pd.read_csv('votes.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "In order to briefly visualize our data:\n",
        "\n",
        "*** (C)** Show the number of lines and columns of `votes`.\n",
        "\n",
        "\n",
        "*** (d)** Show an overview of the first 20 lines of `votes`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "# Dataframa dimensions\n",
        "print('Le DataFrame possède', votes.shape[0], 'lignes et', votes.shape[1], 'colonnes.')\n",
        "\n",
        "# Display of the first 20 lines\n",
        "votes.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        ">*The first column **`\" Party \"`** contains the name of the **political party** to which each member of the Congress of the House of Representatives belongs.\n",
        ">\n",
        ">\n",
        ">*The following columns ** contain the votes of each member of the Congress on proposals of laws:\n",
        ">>*`'There indicates that the elected official voted **for** the bill.\n",
        ">>\n",
        ">>\n",
        ">>*`'only indicates that the elected official voted **against** the bill.\n",
        ">\n",
        "> In order to use the data in a classification model, it is necessary to transform these columns into **digital** Binary values, in other words or 0.\n",
        "\n",
        "*** (e)** For each columns 1 to 16 (column 0 being our target variable), replace the values ​​`'y'' by 1 and` 'by 0. For that, we can use the method **`replace'** of the class` dataframe`.\n",
        "\n",
        "\n",
        "*** (f)** Show the first 10 lines of the modified dataframe` dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "# Replacement of values\n",
        "votes = votes.replace(('y', 'n'), (1, 0))\n",
        "\n",
        "# Dataframa display\n",
        "votes.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "*** (g)** In a dataframe` named `x`, store the variables **Explanatory** of the data game (all columns except` 'Party'`). To do this, you can help yourself with the **`Drop`** method of a dataframe`.\n",
        "\n",
        "\n",
        "*** (h)** in a series called `y ', store the **target variable** (` `party'`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "# Data separation\n",
        "\n",
        "X = votes.drop(['party'], axis = 1)\n",
        "y = votes['party']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "> As for regression, we will have to separate the dataset into 2 parts: a **training game** and a **test** game. As a reminder :\n",
        ">>*The training game is used to **cause the** classification model, that is to say find the parameters of the model that best separate the classes.\n",
        ">>\n",
        ">>\n",
        ">>*The test game is used to **Evaluate** The model on data he has never seen. This evaluation will allow us to judge the ability to generalize ** of the model.\n",
        "\n",
        "*** (i)** Import the function `train_test_Split` sous module` Sklearn.model_selection '. It is recalled that this function is used as follows:\n",
        "> `` python\n",
        "> X_train, x_test, y_train, y_test = train_test_split (x, y, test_size = 0.2)\n",
        "> `` `\n",
        "\n",
        "\n",
        "*** (j)** separate the data into a training game `(x_train, y_train)` and a test game `(x_test, y_test)` while keeping 20% ​​of the data for the test sample.\n",
        ">To eliminate the hazard from the function `train_test_st_stlit`, you can use the` random_state` parameter with an entire value (for example `random_state = 2`).<br>\n",
        "> Thus, each time you use the function with the random_state argument = 2`, the data games produced will be the same.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "> The logistic regression model is closely linked to the linear **regression** seen in the previous notebook.\n",
        ">\n",
        "> Do not confuse them ** since they do not solve the same types of problems:\n",
        ">>*Regression **Logistics** is used for classification (predicting classes).\n",
        ">>\n",
        ">>\n",
        ">>*Linear **regression** is used for regression (predict a quantitative variable).\n",
        ">\n",
        "> The linear regression model was defined by the following formula:\n",
        "> $$ y \\ Approx \\ beta_0 + \\ sum_ {j = 1}^p \\ beta_j x_j $$\n",
        ">\n",
        ">Logistics regression no longer considers $ y $ directly but the ** probability ** that $ y $ is equal to 0 or 1.<br>\n",
        "> Thus, the model is defined by the formula:\n",
        "> $$ p (y = 1) = f (\\ beta_0 + \\ sum_ {j = 1}^p \\ beta_j x_j) $$\n",
        ">\n",
        "> Where $$ f (x) = \\ frac {1} {1 + e^{-x}} $$\n",
        ">\n",
        "> The function $ f $, often called **sigmoid** or **logistical function**, allows you to transform the linear combination $ \\ beta_0 + \\ sum_ {j = 1}^p \\ beta_j x_j $ in a value between 0 and 1 that can be interpreted as a **probability**:\n",
        ">> * If $ \\ beta_0 + \\ sum_ {J = 1}^P \\ beta_j x_j $ is positive, then $ p (y = 1) \\ GT 0.5 $, therefore the predicted class of the observation will be 1.\n",
        ">>\n",
        ">>\n",
        ">> * if $ \\ beta_0 + \\ sum_ {j = 1}^P \\ beta_j x_j $ is negative, then $ p (y = 1) \\ lt 0.5 $, that is to say that $ p (y = 0) \\ GT 0.5 $, so the predicted class of the observation will be 0.\n",
        "\n",
        "*** (K)** Import the class `Logisticregression 'of the submodule` Linear_Model' of `Scikit-Learn`.\n",
        "\n",
        "\n",
        "*** (l)** Install a model `Logisticregression` named **` Logreg`** without specifying any arguments of the manufacturer.\n",
        "\n",
        "\n",
        "*** (m)** Train the model on the training datasets thanks to the `FIT\" method of the Logisticregression 'class.\n",
        "\n",
        "\n",
        "*** (n)** Perform a prediction on **test data**. Store these predictions in **`y_Pred_test_logreg`** and display the first 10 predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "# Import of the Linear_Model Sklearn Linear_Model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instaniation of the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Model training on the training game\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Prediction on test data\n",
        "y_pred_test_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Display of the first 10 predictions\n",
        "print(y_pred_test_logreg[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "## 2. Evaluate the performance of a classification model\n",
        "\n",
        "> There are different metrics to assess the performance of classification models such as:\n",
        ">>*L '**Accuracy**.\n",
        ">> \n",
        ">>\n",
        ">>*** Precision and recall** (*Precision*and*Recall*in English).\n",
        ">\n",
        "> \n",
        "> Each metric assesses the performance of the model with a different approach.\n",
        ">\n",
        "> In order to explain these concepts, we will introduce 4 very important terms.\n",
        ">\n",
        "> **Arbitrarily**, we will choose that the class **'republican' will be the positive class** (1) and **'democrat' will be the negative class** (0).\n",
        ">\n",
        "> Thus, we will call:\n",
        ">>*** True positive (VP)** A classified observation **Positive** ('Republican') by the model and which is actually **positive** ('Republican').\n",
        ">>\n",
        ">>\n",
        ">>*** False positive (FP)** A classified observation **Positive** ('Republican') by the model but which was actually **Negative** ('Democrat').\n",
        ">>\n",
        ">>\n",
        ">> **True negative (vn)** a classified observation **negative** ('democrat') by the model and which is actually **negative** ('democrat').\n",
        ">>\n",
        ">>\n",
        ">>*** False negative (FN)** A classified observation **Negative** ('democrat') by the model but which was actually **positive** ('republican').\n",
        ">\n",
        "><br>\n",
        "><img src = \"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/sklearn_intro_positif_negatif.png\" style = \"height:300px'\">\n",
        "><br>\n",
        ">\n",
        ">The ** battery ** is the most commonly used metric to assess a model.<br>\n",
        "> It simply corresponds to the rate of correct **predictions** carried out by the model.\n",
        ">\n",
        ">We assume that we have $ n $ observations.<br>\n",
        ">We note $ \\ Mathrm {VP} $ the number of real positives and $ \\ Mathrm {vn} $ the number of real negatives.<br>\n",
        "> The battery is then given by:\n",
        "> $$ \\ mathrm {accuracy} = \\ frac {\\ mathrm {vp} + \\ mathrm {vn}} {n} $$\n",
        "> \n",
        "> **Precision** is a metric that answers the question: **Among all the positive predictions of the model, how many are real positives?**\n",
        ">\n",
        "> If we note $ \\ Mathrm {fp} $ the number of false positives of the model, then the precision is given by:\n",
        "> $$ \\ mathrm {precision} = \\ frac {\\ mathrm {vp}} {\\ mathrm {vp} + \\ mathrm {fp}} $$\n",
        ">\n",
        "> A high precision score informs us that the model does not blindly classify all observations as positive.\n",
        "> \n",
        "> The **Reminder** is a metric which quantifies the proportion of truly positive observations which have been correctly classified positive by the model.\n",
        ">\n",
        "> If we note $ \\ mathrm {fn} $ the number of false negatives, then the recall is given by:\n",
        "> $$ \\ mathrm {reminder} = \\ frac {\\ mathrm {vp}} {\\ mathrm {vp} + \\ mathrm {fn}} $$\n",
        ">\n",
        "> A high recall score informs us that the model is capable of detecting really positive observations.\n",
        ">\n",
        "> The **confusion matrix** counts for a dataset the values ​​of VP, VN, FP and FN, which allows us to calculate the three previous metrics:\n",
        ">\n",
        "> $$\n",
        "\\ Mathrm {Confusion Matrix} = \\ Begin {Bmatrix}\n",
        "\\ Mathrm {vn} & \\ Mathrm {fp} \\\\\n",
        "\\ Mathrm {fn} & \\ mathrm {vp}\n",
        "\\ End {Bmatrix}\n",
        " $$\n",
        ">\n",
        "> The function **`Confusion_matrix`** of the submodule` Sklearn.metrics' allows you to generate the confusion matrix from **predictions** of a model:\n",
        ">\n",
        "> `` python\n",
        "> Confusion_matrix (y_true, y_pred)\n",
        ">\n",
        "> `` `\n",
        ">\n",
        ">> **`y_true`** contains the **true** values ​​of y.\n",
        ">>\n",
        ">>\n",
        ">>*** `y_Pred`** contains the values ​​**predicted** by the model.\n",
        ">\n",
        "> The display of the confusion matrix can also be done with the function **`pd.crosstab`**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "*** (A)** Import the functions **`Accident_Score`**, **` Precision_Score`** and **`Recall_Score`** of the submodule` Sklearn.metrics'.\n",
        "\n",
        "\n",
        "*** (B)** Show the Matrix of the predictions of the model **`Logreg`** using **` pd.crosstab`**.\n",
        "\n",
        "\n",
        "*** (C)** Calculate the battery, the precision and the recall of the predictions of the model **`Logreg`**. To use the metrics `Precision_Score` and` Recall_Score`, it will be necessary to inform the argument **`Pos_label = 'Republican''** in order to specify that the class` '' Republican' 'is the positive class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false
      },
      "outputs": [],
      "source": [
        "# Insert your code here\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "function": "solution"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Calculation and display of the confusion matrix\n",
        "print(pd.crosstab(y_test, y_pred_test_logreg, rownames=['Realité'], colnames=['Prédiction']))\n",
        "\n",
        "# Calculation of the battery, precision and reminder\n",
        "print(\"\\nLogReg Accuracy:\", accuracy_score(y_test, y_pred_test_logreg))\n",
        "\n",
        "print(\"\\nLogReg Précision:\", precision_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n",
        "\n",
        "print(\"\\nLogReg Rappel:\", recall_score(y_test, y_pred_test_logreg, pos_label = 'republican'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "\n",
        "# Recap\n",
        "\n",
        "> Scikit-Learn offers many classification models such as **`Logisticregression`**.\n",
        ">\n",
        "> The use of these models is done in the same way for **all** Scikit-Learn models:\n",
        ">>*** instantiation** of the model.\n",
        ">>\n",
        ">> \n",
        ">> **Training** of the model: **`Model.fit (x_train, y_train)`**.\n",
        ">>\n",
        ">>\n",
        ">> **Prediction**: **`Model.Predict (x_test)`**.\n",
        ">\n",
        "> The prediction on the test game allows us to **Evaluate** the performance of the model thanks to **metric** adapted.\n",
        ">\n",
        "> The metrics we have seen are used for the **binary** classification and calculate with 4 values:\n",
        ">>*Real positives: prediction = **+** | Reality = **+**\n",
        ">>\n",
        ">>\n",
        ">>*Real negatives: prediction = **-** | Reality = **-**\n",
        ">>\n",
        ">>\n",
        ">>*False positive: prediction = **+** | Reality = **-**\n",
        ">>\n",
        ">>\n",
        ">>*False negatives: prediction = **-** | Reality = **+**\n",
        ">\n",
        "> All these values ​​can be calculated using the **confusion matrix** generated by the function **`Confusion_matrix`** of the submodule` Sklearn.metrics` or by the function **`Pd.crosstab`**.\n",
        "> \n",
        "> Thanks to these values, we can calculate metrics like:\n",
        ">>*L '**accuracy**: the proportion of correctly classified observations.\n",
        ">>\n",
        ">>\n",
        ">>*** Precision**: The proportion of real positives among all the positive predictions of the model.\n",
        ">>\n",
        ">>\n",
        ">>*The **Reminder**: The proportion of truly positive observations which have been correctly classified positive by the model.\n",
        ">\n",
        "> All these metrics can be obtained using the function **`Classification_Report`** of the submodle **` Sklearn.metrics`**.\n",
        ">\n",
        "# Conclusion and resources\n",
        "\n",
        "> This module made it possible to present the Python programming language and to introduce its main very useful bookstores in the suite (Numpy, Pandas, Scikit-Learn). The Pandas bookstore notably allows you to obtain data in the form of easily manipulable dataframas.\n",
        ">\n",
        "> **If you want to discover a little further methods and in the continuity of this module, you can turn to the \"105 data quality\" module.**\n",
        ">\n",
        "> **If you want to apply the methods presented to other data, you can do it with the \"sandbox\" module. This module consists of a virgin notebook in which data is available and on which you can code freely.**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "owner": "DataScientest"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}